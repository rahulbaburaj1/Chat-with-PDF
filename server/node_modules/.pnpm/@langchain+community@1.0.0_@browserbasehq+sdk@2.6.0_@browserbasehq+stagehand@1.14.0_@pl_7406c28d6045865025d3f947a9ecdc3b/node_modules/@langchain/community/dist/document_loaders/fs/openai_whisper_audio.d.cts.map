{"version":3,"file":"openai_whisper_audio.d.cts","names":["ClientOptions","OpenAIClient","Document","BufferLoader","OpenAIWhisperAudio","Blob","Audio","TranscriptionCreateParams","Partial","Buffer","Record","Promise"],"sources":["../../../src/document_loaders/fs/openai_whisper_audio.d.ts"],"sourcesContent":["import { type ClientOptions, OpenAIClient } from \"@langchain/openai\";\nimport { Document } from \"@langchain/core/documents\";\nimport { BufferLoader } from \"@langchain/classic/document_loaders/fs/buffer\";\n/**\n * @example\n * ```typescript\n * const loader = new OpenAIWhisperAudio(\n *   \"./src/document_loaders/example_data/test.mp3\",\n * );\n * const docs = await loader.load();\n * console.log(docs);\n * ```\n */\nexport declare class OpenAIWhisperAudio extends BufferLoader {\n    private readonly openAIClient;\n    private readonly transcriptionCreateParams?;\n    constructor(filePathOrBlob: string | Blob, fields?: {\n        clientOptions?: ClientOptions;\n        transcriptionCreateParams?: Partial<OpenAIClient.Audio.TranscriptionCreateParams>;\n    });\n    protected parse(raw: Buffer, metadata: Record<string, string>): Promise<Document[]>;\n}\n"],"mappings":";;;;;;;;;;;;;AAaA;;;;;AAKoCQ,cALfJ,kBAAAA,SAA2BD,YAAAA,CAKZK;EAAO,iBAElBC,YAAAA;EAAM,iBAAYC,yBAAAA;EAAM,WAA2BR,CAAAA,cAAAA,EAAAA,MAAAA,GAJnCG,IAImCH,EAAAA,MAPhB,CAOgBA,EAAAA;IAARS,aAAAA,CAAAA,EAH5CX,aAG4CW;IAPpBR,yBAAAA,CAAAA,EAKZK,OALYL,CAKJF,YAAAA,CAAaK,KAAAA,CAAMC,yBALfJ,CAAAA;EAAY,CAAA;uBAOnCM,kBAAkBC,yBAAyBC,QAAQT"}