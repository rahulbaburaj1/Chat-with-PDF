{"version":3,"file":"portkey.d.cts","names":["LLMOptions","Portkey","_Portkey","CallbackManagerForLLMRun","GenerationChunk","LLMResult","BaseLLM","PortkeyOptions","PortkeySession","getPortkeySession","Partial","Promise","AsyncGenerator"],"sources":["../../src/llms/portkey.d.ts"],"sourcesContent":["import { LLMOptions, Portkey as _Portkey } from \"portkey-ai\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { GenerationChunk, LLMResult } from \"@langchain/core/outputs\";\nimport { BaseLLM } from \"@langchain/core/language_models/llms\";\ninterface PortkeyOptions {\n    apiKey?: string;\n    baseURL?: string;\n    mode?: string;\n    llms?: [LLMOptions] | null;\n}\nexport declare class PortkeySession {\n    portkey: _Portkey;\n    constructor(options?: PortkeyOptions);\n}\n/**\n * Get a session for the Portkey API. If one already exists with the same options,\n * it will be returned. Otherwise, a new session will be created.\n * @param options\n * @returns\n */\nexport declare function getPortkeySession(options?: PortkeyOptions): PortkeySession;\n/**\n * @example\n * ```typescript\n * const model = new Portkey({\n *   mode: \"single\",\n *   llms: [\n *     {\n *       provider: \"openai\",\n *       virtual_key: \"open-ai-key-1234\",\n *       model: \"gpt-3.5-turbo-instruct\",\n *       max_tokens: 2000,\n *     },\n *   ],\n * });\n *\n * // Stream the output of the model and process it\n * const res = await model.stream(\n *   \"Question: Write a story about a king\\nAnswer:\"\n * );\n * for await (const i of res) {\n *   process.stdout.write(i);\n * }\n * ```\n */\nexport declare class Portkey extends BaseLLM {\n    apiKey?: string;\n    baseURL?: string;\n    mode?: string;\n    llms?: [LLMOptions] | null;\n    session: PortkeySession;\n    constructor(init?: Partial<Portkey>);\n    _llmType(): string;\n    _generate(prompts: string[], options: this[\"ParsedCallOptions\"], _?: CallbackManagerForLLMRun): Promise<LLMResult>;\n    _streamResponseChunks(input: string, options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;\n}\nexport {};\n"],"mappings":";;;;;;;;;UAIUO,cAAAA;;;;UAIEP;;cAESQ,cAAAA;WACRN;wBACaK;AATqC;AAO/D;;;;AAEwC;AAQxC;AAAyC,iBAAjBE,iBAAAA,CAAiB,OAAA,CAAA,EAAWF,cAAX,CAAA,EAA4BC,cAA5B;;;AAA0C;AAyBnF;;;;;;;;;;;;;AAA4C;;;;;;;;cAAvBP,OAAAA,SAAgBK,OAAAA;;;;UAIzBN;WACCQ;qBACUE,QAAQT;;uEAE0CE,2BAA2BQ,QAAQN;wFAClBF,2BAA2BS,eAAeR"}