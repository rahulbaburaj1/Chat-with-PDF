{"version":3,"file":"perplexity.d.ts","names":["BaseMessage","BaseChatModel","BaseChatModelParams","BaseChatModelCallOptions","CallbackManagerForLLMRun","ChatGenerationChunk","ChatResult","Runnable","BaseLanguageModelInput","StructuredOutputMethodOptions","InteropZodType","PerplexityRole","WebSearchOptions","PerplexityChatInput","PerplexityChatCallOptions","Record","ChatPerplexity","Promise","AsyncGenerator","RunOutput"],"sources":["../../src/chat_models/perplexity.d.ts"],"sourcesContent":["import { BaseMessage } from \"@langchain/core/messages\";\nimport { BaseChatModel, BaseChatModelParams, BaseChatModelCallOptions } from \"@langchain/core/language_models/chat_models\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { ChatGenerationChunk, ChatResult } from \"@langchain/core/outputs\";\nimport { Runnable } from \"@langchain/core/runnables\";\nimport { BaseLanguageModelInput, StructuredOutputMethodOptions } from \"@langchain/core/language_models/base\";\nimport { InteropZodType } from \"@langchain/core/utils/types\";\n/**\n * Type representing the role of a message in the Perplexity chat model.\n */\nexport type PerplexityRole = \"system\" | \"user\" | \"assistant\";\nexport interface WebSearchOptions {\n    /**\n     * Determines how much search context is retrieved for the model.\n     * Options are: low (minimizes context for cost savings but less comprehensive answers), medium (balanced approach suitable for most queries), and high (maximizes context for comprehensive answers but at higher cost).\n     */\n    search_context_size?: \"low\" | \"medium\" | \"high\";\n    /**\n     * To refine search results based on geography, you can specify an approximate user location.\n     */\n    user_location?: {\n        /**\n         * The latitude of the user's location.\n         */\n        latitude: number;\n        /**\n         * The longitude of the user's location.\n         */\n        longitude: number;\n        /**\n         * The two letter ISO country code of the user's location.\n         */\n        country: string;\n    };\n}\n/**\n * Interface defining the parameters for the Perplexity chat model.\n */\nexport interface PerplexityChatInput extends BaseChatModelParams {\n    /** Model name to use */\n    model: string;\n    /** Maximum number of tokens to generate */\n    maxTokens?: number;\n    /** Temperature parameter between 0 and 2 */\n    temperature?: number;\n    /** Top P parameter between 0 and 1 */\n    topP?: number;\n    /** Search domain filter - limit the citations used by the online model to URLs from the specified domains. */\n    searchDomainFilter?: unknown[];\n    /** Whether to return images */\n    returnImages?: boolean;\n    /** Determines whether or not a request to an online model should return related questions. */\n    returnRelatedQuestions?: boolean;\n    /** Returns search results within the specified time interval - does not apply to images. Values include month, week, day, hour. */\n    searchRecencyFilter?: string;\n    /** Top K parameter between 1 and 2048 */\n    topK?: number;\n    /** Presence penalty between -2 and 2 */\n    presencePenalty?: number;\n    /** Frequency penalty greater than 0 */\n    frequencyPenalty?: number;\n    /** API key for Perplexity.  Defaults to the value of\n     * PERPLEXITY_API_KEY environment variable.\n     */\n    apiKey?: string;\n    /** Whether to stream the results or not */\n    streaming?: boolean;\n    /** Timeout for requests to Perplexity */\n    timeout?: number;\n    /** Controls the search mode used for the request. When set to 'academic', results will prioritize scholarly sources. */\n    searchMode?: \"academic\" | \"web\";\n    /** Controls how much computational effort the AI dedicates to each query for deep research models. Only applicable for sonar-deep-research. */\n    reasoningEffort?: \"low\" | \"medium\" | \"high\";\n    /** Filters search results to only include content published after this date. */\n    searchAfterDateFilter?: string;\n    /** Filters search results to only include content published before this date. */\n    searchBeforeDateFilter?: string;\n    /** Filters search results to only include content last updated after this date. */\n    lastUpdatedAfterFilter?: string;\n    /** Filters search results to only include content last updated before this date. */\n    lastUpdatedBeforeFilter?: string;\n    /** When set to true, disables web search completely and the model will only use its training data to respond. This is useful when you want deterministic responses without external information. */\n    disableSearch?: boolean;\n    /** Enables a classifier that decides if web search is needed based on your query. */\n    enableSearchClassifier?: boolean;\n    /**\n     * Configuration for using web search in model responses.\n     */\n    webSearchOptions?: WebSearchOptions;\n}\nexport interface PerplexityChatCallOptions extends BaseChatModelCallOptions {\n    response_format?: {\n        type: \"json_schema\";\n        json_schema: {\n            name: string;\n            description: string;\n            schema: Record<string, unknown>;\n        };\n    };\n}\n/**\n * Wrapper around Perplexity large language models that use the Chat endpoint.\n */\nexport declare class ChatPerplexity extends BaseChatModel<PerplexityChatCallOptions> implements PerplexityChatInput {\n    static lc_name(): string;\n    model: string;\n    temperature?: number;\n    maxTokens?: number;\n    apiKey?: string;\n    timeout?: number;\n    streaming?: boolean;\n    topP?: number;\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    searchDomainFilter?: any[];\n    returnImages?: boolean;\n    returnRelatedQuestions?: boolean;\n    searchRecencyFilter?: string;\n    topK?: number;\n    presencePenalty?: number;\n    frequencyPenalty?: number;\n    searchMode?: \"academic\" | \"web\";\n    reasoningEffort?: \"low\" | \"medium\" | \"high\";\n    searchAfterDateFilter?: string;\n    searchBeforeDateFilter?: string;\n    lastUpdatedAfterFilter?: string;\n    lastUpdatedBeforeFilter?: string;\n    disableSearch?: boolean;\n    enableSearchClassifier?: boolean;\n    webSearchOptions?: WebSearchOptions;\n    private client;\n    constructor(fields: PerplexityChatInput);\n    _llmType(): string;\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options?: this[\"ParsedCallOptions\"]): {\n        model: string;\n        temperature: number | undefined;\n        max_tokens: number | undefined;\n        stream: boolean | undefined;\n        top_p: number | undefined;\n        return_images: boolean | undefined;\n        return_related_questions: boolean | undefined;\n        top_k: number | undefined;\n        presence_penalty: number | undefined;\n        frequency_penalty: number | undefined;\n        response_format: {\n            type: \"json_schema\";\n            json_schema: {\n                name: string;\n                description: string;\n                schema: Record<string, unknown>;\n            };\n        } | undefined;\n        search_domain_filter: any[] | undefined;\n        search_recency_filter: string | undefined;\n        search_mode: \"academic\" | \"web\" | undefined;\n        reasoning_effort: \"high\" | \"low\" | \"medium\" | undefined;\n        search_after_date_filter: string | undefined;\n        search_before_date_filter: string | undefined;\n        last_updated_after_filter: string | undefined;\n        last_updated_before_filter: string | undefined;\n        disable_search: boolean | undefined;\n        enable_search_classifier: boolean | undefined;\n        web_search_options: Record<string, unknown>;\n    };\n    /**\n     * Convert a message to a format that the model expects\n     */\n    private messageToPerplexityRole;\n    _generate(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    _streamResponseChunks(messages: BaseMessage[], options: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    withStructuredOutput<\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    RunOutput extends Record<string, any> = Record<string, any>>(outputSchema: InteropZodType<RunOutput>\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n     | Record<string, any>, config?: StructuredOutputMethodOptions<false>): Runnable<BaseLanguageModelInput, RunOutput>;\n    withStructuredOutput<\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    RunOutput extends Record<string, any> = Record<string, any>>(outputSchema: InteropZodType<RunOutput>\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n     | Record<string, any>, config?: StructuredOutputMethodOptions<true>): Runnable<BaseLanguageModelInput, {\n        raw: BaseMessage;\n        parsed: RunOutput;\n    }>;\n}\n"],"mappings":";;;;;;;;;;;;;;;KAUYW,cAAAA;UACKC,gBAAAA;;;;;;;AADjB;AACA;EA2BiBC,aAAAA,CAAAA,EAAAA;IAAmB;;;IAA4B,QAAA,EAAA,MAAA;IAoD/CC;;;IAAkCX,SAAAA,EAAAA,MAAAA;IAAwB;AAa3E;;IAA0DW,OAAAA,EAAAA,MAAAA;EAAyB,CAAA;;;;;AAmEKV,UApIvES,mBAAAA,SAA4BX,mBAoI2CE,CAAAA;EAAwB;EAAqB,KAAlBa,EAAAA,MAAAA;EAAO;EAC3E,SAAqDb,CAAAA,EAAAA,MAAAA;EAAwB;EAAqC,WAAlCc,CAAAA,EAAAA,MAAAA;EAAc;EAGjH,IAAgBH,CAAAA,EAAAA,MAAAA;EAAM;EAAqD,kBAAxBL,CAAAA,EAAAA,OAAAA,EAAAA;EAAc;EAEhF,YAAwBD,CAAAA,EAAAA,OAAAA;EAA6B;EAAyC,sBAAEU,CAAAA,EAAAA,OAAAA;EAAS;EAAlC,mBAG9DJ,CAAAA,EAAAA,MAAAA;EAAM;EAAsB,IAA4CI,CAAAA,EAAAA,MAAAA;EAAS;EAAV,eAEtFJ,CAAAA,EAAAA,MAAAA;EAAM;EAAqD,gBAAkBP,CAAAA,EAAAA,MAAAA;EAAsB;;;EAAvB,MA9EvCP,CAAAA,EAAAA,MAAAA;EAAa;EAA0D,SAAA,CAAA,EAAA,OAAA;;;;;;;;;;;;;;;;;;;;;;qBAf5FW;;UAENE,yBAAAA,SAAkCX;;;;;;cAM/BY;;;;;;;cAOCC,cAAAA,SAAuBf,cAAca,sCAAsCD;;;;;;;;;;;;;;;;;;;;;;;;;qBAyBzED;;sBAECC;;;;;;;;;;;;;;;;;;;;;gBAqBAE;;;;;;;;;;;;;wBAaIA;;;;;;sBAMJf,gEAAgEI,2BAA2Ba,QAAQX;kCACvFN,gEAAgEI,2BAA2Bc,eAAeb;;;oBAGxHU,sBAAsBA,mCAAmCL,eAAeS;;IAEvFJ,8BAA8BN,uCAAuCF,SAASC,wBAAwBW;;;oBAGvFJ,sBAAsBA,mCAAmCL,eAAeS;;IAEvFJ,8BAA8BN,sCAAsCF,SAASC;SACvER;YACGmB"}