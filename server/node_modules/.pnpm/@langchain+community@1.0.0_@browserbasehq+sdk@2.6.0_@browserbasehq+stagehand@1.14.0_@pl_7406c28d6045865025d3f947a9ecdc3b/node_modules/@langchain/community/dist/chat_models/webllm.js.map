{"version":3,"file":"webllm.js","names":["inputs: WebLLMInputs","progressCallback?: webllm.InitProgressCallback","modelId: string","newChatOpts?: webllm.ChatOptions","messages: BaseMessage[]","options: this[\"ParsedCallOptions\"]","runManager?: CallbackManagerForLLMRun","messagesInput: ChatCompletionMessageParam[]"],"sources":["../../src/chat_models/webllm.ts"],"sourcesContent":["import {\n  SimpleChatModel,\n  type BaseChatModelParams,\n} from \"@langchain/core/language_models/chat_models\";\nimport type { BaseLanguageModelCallOptions } from \"@langchain/core/language_models/base\";\nimport { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { BaseMessage, AIMessageChunk } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk } from \"@langchain/core/outputs\";\nimport * as webllm from \"@mlc-ai/web-llm\";\nimport { ChatCompletionMessageParam } from \"@mlc-ai/web-llm/lib/openai_api_protocols\";\n\nexport interface WebLLMInputs extends BaseChatModelParams {\n  appConfig?: webllm.AppConfig;\n  chatOptions?: webllm.ChatOptions;\n  temperature?: number;\n  model: string;\n}\n\nexport interface WebLLMCallOptions extends BaseLanguageModelCallOptions {}\n\n/**\n * To use this model you need to have the `@mlc-ai/web-llm` module installed.\n * This can be installed using `npm install -S @mlc-ai/web-llm`.\n *\n * You can see a list of available model records here:\n * https://github.com/mlc-ai/web-llm/blob/main/src/config.ts\n * @example\n * ```typescript\n * // Initialize the ChatWebLLM model with the model record.\n * const model = new ChatWebLLM({\n *   model: \"Phi-3-mini-4k-instruct-q4f16_1-MLC\",\n *   chatOptions: {\n *     temperature: 0.5,\n *   },\n * });\n *\n * // Call the model with a message and await the response.\n * const response = await model.invoke([\n *   new HumanMessage({ content: \"My name is John.\" }),\n * ]);\n * ```\n */\nexport class ChatWebLLM extends SimpleChatModel<WebLLMCallOptions> {\n  static inputs: WebLLMInputs;\n\n  protected engine: webllm.MLCEngine;\n\n  appConfig?: webllm.AppConfig;\n\n  chatOptions?: webllm.ChatOptions;\n\n  temperature?: number;\n\n  model: string;\n\n  static lc_name() {\n    return \"ChatWebLLM\";\n  }\n\n  constructor(inputs: WebLLMInputs) {\n    super(inputs);\n    this.appConfig = inputs.appConfig;\n    this.chatOptions = inputs.chatOptions;\n    this.model = inputs.model;\n    this.temperature = inputs.temperature;\n    this.engine = new webllm.MLCEngine({\n      appConfig: this.appConfig,\n    });\n  }\n\n  _llmType() {\n    return \"web-llm\";\n  }\n\n  async initialize(progressCallback?: webllm.InitProgressCallback) {\n    if (progressCallback !== undefined) {\n      this.engine.setInitProgressCallback(progressCallback);\n    }\n    await this.reload(this.model, this.chatOptions);\n  }\n\n  async reload(modelId: string, newChatOpts?: webllm.ChatOptions) {\n    await this.engine.reload(modelId, newChatOpts);\n  }\n\n  async *_streamResponseChunks(\n    messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): AsyncGenerator<ChatGenerationChunk> {\n    const messagesInput: ChatCompletionMessageParam[] = messages.map(\n      (message) => {\n        if (typeof message.content !== \"string\") {\n          throw new Error(\n            \"ChatWebLLM does not support non-string message content in sessions.\"\n          );\n        }\n        const langChainType = message._getType();\n        let role;\n        if (langChainType === \"ai\") {\n          role = \"assistant\" as const;\n        } else if (langChainType === \"human\") {\n          role = \"user\" as const;\n        } else if (langChainType === \"system\") {\n          role = \"system\" as const;\n        } else {\n          throw new Error(\n            \"Function, tool, and generic messages are not supported.\"\n          );\n        }\n        return {\n          role,\n          content: message.content,\n        };\n      }\n    );\n\n    const stream = await this.engine.chat.completions.create({\n      stream: true,\n      messages: messagesInput,\n      stop: options.stop,\n      logprobs: true,\n    });\n    for await (const chunk of stream) {\n      // Last chunk has undefined content\n      const text = chunk.choices[0].delta.content ?? \"\";\n      yield new ChatGenerationChunk({\n        text,\n        message: new AIMessageChunk({\n          content: text,\n          additional_kwargs: {\n            logprobs: chunk.choices[0].logprobs,\n            finish_reason: chunk.choices[0].finish_reason,\n          },\n        }),\n      });\n      await runManager?.handleLLMNewToken(text);\n    }\n  }\n\n  async _call(\n    messages: BaseMessage[],\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<string> {\n    const chunks = [];\n    for await (const chunk of this._streamResponseChunks(\n      messages,\n      options,\n      runManager\n    )) {\n      chunks.push(chunk.text);\n    }\n    return chunks.join(\"\");\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0CA,IAAa,aAAb,cAAgC,gBAAmC;CACjE,OAAO;CAEP,AAAU;CAEV;CAEA;CAEA;CAEA;CAEA,OAAO,UAAU;AACf,SAAO;CACR;CAED,YAAYA,QAAsB;EAChC,MAAM,OAAO;EACb,KAAK,YAAY,OAAO;EACxB,KAAK,cAAc,OAAO;EAC1B,KAAK,QAAQ,OAAO;EACpB,KAAK,cAAc,OAAO;EAC1B,KAAK,SAAS,IAAI,OAAO,UAAU,EACjC,WAAW,KAAK,UACjB;CACF;CAED,WAAW;AACT,SAAO;CACR;CAED,MAAM,WAAWC,kBAAgD;AAC/D,MAAI,qBAAqB,QACvB,KAAK,OAAO,wBAAwB,iBAAiB;EAEvD,MAAM,KAAK,OAAO,KAAK,OAAO,KAAK,YAAY;CAChD;CAED,MAAM,OAAOC,SAAiBC,aAAkC;EAC9D,MAAM,KAAK,OAAO,OAAO,SAAS,YAAY;CAC/C;CAED,OAAO,sBACLC,UACAC,SACAC,YACqC;EACrC,MAAMC,gBAA8C,SAAS,IAC3D,CAAC,YAAY;AACX,OAAI,OAAO,QAAQ,YAAY,SAC7B,OAAM,IAAI,MACR;GAGJ,MAAM,gBAAgB,QAAQ,UAAU;GACxC,IAAI;AACJ,OAAI,kBAAkB,MACpB,OAAO;YACE,kBAAkB,SAC3B,OAAO;YACE,kBAAkB,UAC3B,OAAO;OAEP,OAAM,IAAI,MACR;AAGJ,UAAO;IACL;IACA,SAAS,QAAQ;GAClB;EACF,EACF;EAED,MAAM,SAAS,MAAM,KAAK,OAAO,KAAK,YAAY,OAAO;GACvD,QAAQ;GACR,UAAU;GACV,MAAM,QAAQ;GACd,UAAU;EACX,EAAC;AACF,aAAW,MAAM,SAAS,QAAQ;GAEhC,MAAM,OAAO,MAAM,QAAQ,GAAG,MAAM,WAAW;GAC/C,MAAM,IAAI,oBAAoB;IAC5B;IACA,SAAS,IAAI,eAAe;KAC1B,SAAS;KACT,mBAAmB;MACjB,UAAU,MAAM,QAAQ,GAAG;MAC3B,eAAe,MAAM,QAAQ,GAAG;KACjC;IACF;GACF;GACD,MAAM,YAAY,kBAAkB,KAAK;EAC1C;CACF;CAED,MAAM,MACJH,UACAC,SACAC,YACiB;EACjB,MAAM,SAAS,CAAE;AACjB,aAAW,MAAM,SAAS,KAAK,sBAC7B,UACA,SACA,WACD,EACC,OAAO,KAAK,MAAM,KAAK;AAEzB,SAAO,OAAO,KAAK,GAAG;CACvB;AACF"}