{"version":3,"file":"ioredis.js","names":["redisClient: Redis","config?: {\n      ttl?: number;\n    }","prompt: string","llmKey: string","generations: Generation[]","value: Generation[]"],"sources":["../../src/caches/ioredis.ts"],"sourcesContent":["import { Redis } from \"ioredis\";\nimport {\n  BaseCache,\n  serializeGeneration,\n  deserializeStoredGeneration,\n} from \"@langchain/core/caches\";\nimport { Generation } from \"@langchain/core/outputs\";\n\n/**\n * Cache LLM results using Redis.\n * @example\n * ```typescript\n * const model = new ChatOpenAI({\n *   model: \"gpt-4o-mini\",\n *   cache: new RedisCache(new Redis(), { ttl: 60 }),\n * });\n *\n * // Invoke the model with a prompt\n * const response = await model.invoke(\"Do something random!\");\n * console.log(response);\n *\n * // Remember to disconnect the Redis client when done\n * await redisClient.disconnect();\n * ```\n */\nexport class RedisCache extends BaseCache {\n  protected redisClient: Redis;\n\n  protected ttl?: number;\n\n  constructor(\n    redisClient: Redis,\n    config?: {\n      ttl?: number;\n    }\n  ) {\n    super();\n    this.redisClient = redisClient;\n    this.ttl = config?.ttl;\n  }\n\n  /**\n   * Retrieves data from the Redis server using a prompt and an LLM key. If\n   * the data is not found, it returns null.\n   * @param prompt The prompt used to find the data.\n   * @param llmKey The LLM key used to find the data.\n   * @returns The corresponding data as an array of Generation objects, or null if not found.\n   */\n  public async lookup(prompt: string, llmKey: string) {\n    let idx = 0;\n    let key = this.keyEncoder(prompt, llmKey, String(idx));\n    let value = await this.redisClient.get(key);\n    const generations: Generation[] = [];\n\n    while (value) {\n      const storedGeneration = JSON.parse(value);\n      generations.push(deserializeStoredGeneration(storedGeneration));\n      idx += 1;\n      key = this.keyEncoder(prompt, llmKey, String(idx));\n      value = await this.redisClient.get(key);\n    }\n\n    return generations.length > 0 ? generations : null;\n  }\n\n  /**\n   * Updates the data in the Redis server using a prompt and an LLM key.\n   * @param prompt The prompt used to store the data.\n   * @param llmKey The LLM key used to store the data.\n   * @param value The data to be stored, represented as an array of Generation objects.\n   */\n  public async update(prompt: string, llmKey: string, value: Generation[]) {\n    for (let i = 0; i < value.length; i += 1) {\n      const key = this.keyEncoder(prompt, llmKey, String(i));\n      if (this.ttl !== undefined) {\n        await this.redisClient.set(\n          key,\n          JSON.stringify(serializeGeneration(value[i])),\n          \"EX\",\n          this.ttl\n        );\n      } else {\n        await this.redisClient.set(\n          key,\n          JSON.stringify(serializeGeneration(value[i]))\n        );\n      }\n    }\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAyBA,IAAa,aAAb,cAAgC,UAAU;CACxC,AAAU;CAEV,AAAU;CAEV,YACEA,aACAC,QAGA;EACA,OAAO;EACP,KAAK,cAAc;EACnB,KAAK,MAAM,QAAQ;CACpB;;;;;;;;CASD,MAAa,OAAOC,QAAgBC,QAAgB;EAClD,IAAI,MAAM;EACV,IAAI,MAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,IAAI,CAAC;EACtD,IAAI,QAAQ,MAAM,KAAK,YAAY,IAAI,IAAI;EAC3C,MAAMC,cAA4B,CAAE;AAEpC,SAAO,OAAO;GACZ,MAAM,mBAAmB,KAAK,MAAM,MAAM;GAC1C,YAAY,KAAK,4BAA4B,iBAAiB,CAAC;GAC/D,OAAO;GACP,MAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,IAAI,CAAC;GAClD,QAAQ,MAAM,KAAK,YAAY,IAAI,IAAI;EACxC;AAED,SAAO,YAAY,SAAS,IAAI,cAAc;CAC/C;;;;;;;CAQD,MAAa,OAAOF,QAAgBC,QAAgBE,OAAqB;AACvE,OAAK,IAAI,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,GAAG;GACxC,MAAM,MAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,EAAE,CAAC;AACtD,OAAI,KAAK,QAAQ,QACf,MAAM,KAAK,YAAY,IACrB,KACA,KAAK,UAAU,oBAAoB,MAAM,GAAG,CAAC,EAC7C,MACA,KAAK,IACN;QAED,MAAM,KAAK,YAAY,IACrB,KACA,KAAK,UAAU,oBAAoB,MAAM,GAAG,CAAC,CAC9C;EAEJ;CACF;AACF"}