import { AgentMiddleware } from "./types.cjs";
import * as _langchain_core_language_models_base0 from "@langchain/core/language_models/base";
import { BaseLanguageModel } from "@langchain/core/language_models/base";
import { InferInteropZodInput } from "@langchain/core/utils/types";
import { z } from "zod/v3";

//#region src/agents/middleware/summarization.d.ts
declare const contextSchema: z.ZodObject<{
  model: z.ZodType<BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>, z.ZodTypeDef, BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>>;
  maxTokensBeforeSummary: z.ZodOptional<z.ZodNumber>;
  messagesToKeep: z.ZodDefault<z.ZodNumber>;
  tokenCounter: z.ZodOptional<z.ZodFunction<z.ZodTuple<[z.ZodArray<z.ZodAny, "many">], z.ZodUnknown>, z.ZodUnion<[z.ZodNumber, z.ZodPromise<z.ZodNumber>]>>>;
  summaryPrompt: z.ZodDefault<z.ZodString>;
  summaryPrefix: z.ZodDefault<z.ZodString>;
}, "strip", z.ZodTypeAny, {
  model: BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>;
  maxTokensBeforeSummary?: number | undefined;
  messagesToKeep: number;
  tokenCounter?: ((args_0: any[], ...args: unknown[]) => number | Promise<number>) | undefined;
  summaryPrompt: string;
  summaryPrefix: string;
}, {
  model: BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>;
  maxTokensBeforeSummary?: number | undefined;
  messagesToKeep?: number | undefined;
  tokenCounter?: ((args_0: any[], ...args: unknown[]) => number | Promise<number>) | undefined;
  summaryPrompt?: string | undefined;
  summaryPrefix?: string | undefined;
}>;
type SummarizationMiddlewareConfig = InferInteropZodInput<typeof contextSchema>;
/**
 * Summarization middleware that automatically summarizes conversation history when token limits are approached.
 *
 * This middleware monitors message token counts and automatically summarizes older
 * messages when a threshold is reached, preserving recent messages and maintaining
 * context continuity by ensuring AI/Tool message pairs remain together.
 *
 * @param options Configuration options for the summarization middleware
 * @returns A middleware instance
 *
 * @example
 * ```ts
 * import { summarizationMiddleware } from "langchain";
 * import { createAgent } from "langchain";
 *
 * const agent = createAgent({
 *   llm: model,
 *   tools: [getWeather],
 *   middleware: [
 *     summarizationMiddleware({
 *       model: new ChatOpenAI({ model: "gpt-4o" }),
 *       maxTokensBeforeSummary: 4000,
 *       messagesToKeep: 20,
 *     })
 *   ],
 * });
 *
 * ```
 */
declare function summarizationMiddleware(options: SummarizationMiddlewareConfig): AgentMiddleware<undefined, z.ZodObject<{
  model: z.ZodType<BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>, z.ZodTypeDef, BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>>;
  maxTokensBeforeSummary: z.ZodOptional<z.ZodNumber>;
  messagesToKeep: z.ZodDefault<z.ZodNumber>;
  tokenCounter: z.ZodOptional<z.ZodFunction<z.ZodTuple<[z.ZodArray<z.ZodAny, "many">], z.ZodUnknown>, z.ZodUnion<[z.ZodNumber, z.ZodPromise<z.ZodNumber>]>>>;
  summaryPrompt: z.ZodDefault<z.ZodString>;
  summaryPrefix: z.ZodDefault<z.ZodString>;
}, "strip", z.ZodTypeAny, {
  model: BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>;
  maxTokensBeforeSummary?: number | undefined;
  messagesToKeep: number;
  tokenCounter?: ((args_0: any[], ...args: unknown[]) => number | Promise<number>) | undefined;
  summaryPrompt: string;
  summaryPrefix: string;
}, {
  model: BaseLanguageModel<any, _langchain_core_language_models_base0.BaseLanguageModelCallOptions>;
  maxTokensBeforeSummary?: number | undefined;
  messagesToKeep?: number | undefined;
  tokenCounter?: ((args_0: any[], ...args: unknown[]) => number | Promise<number>) | undefined;
  summaryPrompt?: string | undefined;
  summaryPrefix?: string | undefined;
}>, any>;
//#endregion
export { SummarizationMiddlewareConfig, summarizationMiddleware };
//# sourceMappingURL=summarization.d.cts.map