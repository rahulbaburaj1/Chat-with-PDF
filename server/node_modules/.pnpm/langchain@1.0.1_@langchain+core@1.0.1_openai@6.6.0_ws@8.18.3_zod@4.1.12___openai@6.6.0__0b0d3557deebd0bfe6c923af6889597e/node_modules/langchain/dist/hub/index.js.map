{"version":3,"file":"index.js","names":["ownerRepoCommit: string","options?: {\n    apiKey?: string;\n    apiUrl?: string;\n    includeModel?: boolean;\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    modelClass?: new (...args: any[]) => BaseLanguageModel;\n  }","e: any"],"sources":["../../src/hub/index.ts"],"sourcesContent":["import { Runnable } from \"@langchain/core/runnables\";\nimport type { BaseLanguageModel } from \"@langchain/core/language_models/base\";\nimport { load } from \"../load/index.js\";\nimport {\n  basePush,\n  basePull,\n  generateModelImportMap,\n  generateOptionalImportMap,\n  bindOutputSchema,\n} from \"./base.js\";\n\nexport { basePush as push };\n\n/**\n * Pull a prompt from the hub.\n *\n * @param ownerRepoCommit The name of the repo containing the prompt, as well as an optional commit hash separated by a slash.\n * @param options.apiKey LangSmith API key to use when pulling the prompt\n * @param options.apiUrl LangSmith API URL to use when pulling the prompt\n * @param options.includeModel Whether to also instantiate and attach a model instance to the prompt,\n *   if the prompt has associated model metadata. If set to true, invoking the resulting pulled prompt will\n *   also invoke the instantiated model. For non-OpenAI models, you must also set \"modelClass\" to the\n *   correct class of the model.\n * @param options.modelClass If includeModel is true, the class of the model to instantiate. Required\n *   for non-OpenAI models. If you are running in Node or another environment that supports dynamic imports,\n *   you may instead import this function from \"langchain/hub/node\" and pass \"includeModel: true\" instead\n *   of specifying this parameter.\n * @returns\n */\nexport async function pull<T extends Runnable>(\n  ownerRepoCommit: string,\n  options?: {\n    apiKey?: string;\n    apiUrl?: string;\n    includeModel?: boolean;\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    modelClass?: new (...args: any[]) => BaseLanguageModel;\n  }\n) {\n  const promptObject = await basePull(ownerRepoCommit, options);\n  try {\n    const loadedPrompt = await load<T>(\n      JSON.stringify(promptObject.manifest),\n      undefined,\n      generateOptionalImportMap(options?.modelClass),\n      generateModelImportMap(options?.modelClass)\n    );\n    return bindOutputSchema(loadedPrompt);\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  } catch (e: any) {\n    if (options?.includeModel) {\n      throw new Error(\n        [\n          e.message,\n          \"\",\n          `To load prompts with an associated non-OpenAI model, you must use the \"langchain/hub/node\" entrypoint, or pass a \"modelClass\" parameter like this:`,\n          \"\",\n          \"```\",\n          `import { pull } from \"langchain/hub\";`,\n          `import { ChatAnthropic } from \"@langchain/anthropic\";`,\n          \"\",\n          `const prompt = await pull(\"my-prompt\", {`,\n          `  includeModel: true,`,\n          `  modelClass: ChatAnthropic,`,\n          `});`,\n          \"```\",\n        ].join(\"\\n\")\n      );\n    } else {\n      throw e;\n    }\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;AA6BA,eAAsB,KACpBA,iBACAC,SAOA;CACA,MAAM,eAAe,MAAM,SAAS,iBAAiB,QAAQ;AAC7D,KAAI;EACF,MAAM,eAAe,MAAM,KACzB,KAAK,UAAU,aAAa,SAAS,EACrC,QACA,0BAA0B,SAAS,WAAW,EAC9C,uBAAuB,SAAS,WAAW,CAC5C;AACD,SAAO,iBAAiB,aAAa;CAEtC,SAAQC,GAAQ;AACf,MAAI,SAAS,aACX,OAAM,IAAI,MACR;GACE,EAAE;GACF;GACA,CAAC,kJAAkJ,CAAC;GACpJ;GACA;GACA,CAAC,qCAAqC,CAAC;GACvC,CAAC,qDAAqD,CAAC;GACvD;GACA,CAAC,wCAAwC,CAAC;GAC1C,CAAC,qBAAqB,CAAC;GACvB,CAAC,4BAA4B,CAAC;GAC9B,CAAC,GAAG,CAAC;GACL;EACD,EAAC,KAAK,KAAK;MAGd,OAAM;CAET;AACF"}