{"version":3,"file":"chat_models.js","names":["fields?: AzureChatOpenAIFields","options: OpenAICoreRequestOptions | undefined","openAIEndpointConfig: OpenAIEndpointConfig","AzureOpenAIClient","input: Serialized","obj: unknown","options: this[\"ParsedCallOptions\"]","config: StructuredOutputMethodOptions<boolean>"],"sources":["../../src/azure/chat_models.ts"],"sourcesContent":["import { AzureOpenAI as AzureOpenAIClient } from \"openai\";\nimport { getEnv, getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport type { Serialized } from \"@langchain/core/load/serializable\";\nimport { LangSmithParams } from \"@langchain/core/language_models/chat_models\";\nimport { StructuredOutputMethodOptions } from \"@langchain/core/language_models/base\";\nimport {\n  BaseChatOpenAI,\n  BaseChatOpenAIFields,\n  ChatOpenAI,\n  ChatOpenAICallOptions,\n  ChatOpenAICompletions,\n  ChatOpenAICompletionsCallOptions,\n  ChatOpenAIResponses,\n  ChatOpenAIResponsesCallOptions,\n} from \"../chat_models.js\";\nimport {\n  OpenAIEndpointConfig,\n  getEndpoint,\n  normalizeHeaders,\n} from \"../utils/azure.js\";\nimport {\n  AzureOpenAIChatInput,\n  AzureOpenAIInput,\n  OpenAICoreRequestOptions,\n} from \"../types.js\";\n\nexport type { AzureOpenAIInput };\n\nconst AZURE_ALIASES = {\n  openAIApiKey: \"openai_api_key\",\n  openAIApiVersion: \"openai_api_version\",\n  openAIBasePath: \"openai_api_base\",\n  deploymentName: \"deployment_name\",\n  azureOpenAIEndpoint: \"azure_endpoint\",\n  azureOpenAIApiVersion: \"openai_api_version\",\n  azureOpenAIBasePath: \"openai_api_base\",\n  azureOpenAIApiDeploymentName: \"deployment_name\",\n};\n\nconst AZURE_SECRETS = {\n  azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n};\n\nconst AZURE_SERIALIZABLE_KEYS = [\n  \"azureOpenAIApiKey\",\n  \"azureOpenAIApiVersion\",\n  \"azureOpenAIBasePath\",\n  \"azureOpenAIEndpoint\",\n  \"azureOpenAIApiInstanceName\",\n  \"azureOpenAIApiDeploymentName\",\n  \"deploymentName\",\n  \"openAIApiKey\",\n  \"openAIApiVersion\",\n];\n\nfunction _constructAzureFields(\n  this: Partial<AzureOpenAIChatInput>,\n  fields?: AzureChatOpenAIFields\n) {\n  this.azureOpenAIApiKey =\n    fields?.azureOpenAIApiKey ??\n    fields?.openAIApiKey ??\n    fields?.apiKey ??\n    getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n\n  this.azureOpenAIApiInstanceName =\n    fields?.azureOpenAIApiInstanceName ??\n    getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n\n  this.azureOpenAIApiDeploymentName =\n    fields?.azureOpenAIApiDeploymentName ??\n    fields?.deploymentName ??\n    getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\");\n\n  this.azureOpenAIApiVersion =\n    fields?.azureOpenAIApiVersion ??\n    fields?.openAIApiVersion ??\n    getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n\n  this.azureOpenAIBasePath =\n    fields?.azureOpenAIBasePath ??\n    getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n\n  this.azureOpenAIEndpoint =\n    fields?.azureOpenAIEndpoint ??\n    getEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\");\n\n  this.azureADTokenProvider = fields?.azureADTokenProvider;\n\n  if (!this.azureOpenAIApiKey && !this.apiKey && !this.azureADTokenProvider) {\n    throw new Error(\"Azure OpenAI API key or Token Provider not found\");\n  }\n}\n\nfunction _getAzureClientOptions(\n  this: BaseChatOpenAI<ChatOpenAICallOptions> & Partial<AzureOpenAIChatInput>,\n  options: OpenAICoreRequestOptions | undefined\n) {\n  if (!this.client) {\n    const openAIEndpointConfig: OpenAIEndpointConfig = {\n      azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n      azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n      azureOpenAIApiKey: this.azureOpenAIApiKey,\n      azureOpenAIBasePath: this.azureOpenAIBasePath,\n      azureADTokenProvider: this.azureADTokenProvider,\n      baseURL: this.clientConfig.baseURL,\n      azureOpenAIEndpoint: this.azureOpenAIEndpoint,\n    };\n\n    const endpoint = getEndpoint(openAIEndpointConfig);\n\n    const params = {\n      ...this.clientConfig,\n      baseURL: endpoint,\n      timeout: this.timeout,\n      maxRetries: 0,\n    };\n\n    if (!this.azureADTokenProvider) {\n      params.apiKey = openAIEndpointConfig.azureOpenAIApiKey;\n    }\n\n    if (!params.baseURL) {\n      delete params.baseURL;\n    }\n\n    let env = getEnv();\n    if (env === \"node\" || env === \"deno\") {\n      env = `(${env}/${process.version}; ${process.platform}; ${process.arch})`;\n    }\n\n    const defaultHeaders = normalizeHeaders(params.defaultHeaders);\n    params.defaultHeaders = {\n      ...params.defaultHeaders,\n      \"User-Agent\": defaultHeaders[\"User-Agent\"]\n        ? `langchainjs-azure-openai/2.0.0 (${env})${defaultHeaders[\"User-Agent\"]}`\n        : `langchainjs-azure-openai/2.0.0 (${env})`,\n    };\n\n    this.client = new AzureOpenAIClient({\n      apiVersion: this.azureOpenAIApiVersion,\n      azureADTokenProvider: this.azureADTokenProvider,\n      deployment: this.azureOpenAIApiDeploymentName,\n      ...params,\n    });\n  }\n  const requestOptions = {\n    ...this.clientConfig,\n    ...options,\n  } as OpenAICoreRequestOptions;\n  if (this.azureOpenAIApiKey) {\n    requestOptions.headers = {\n      \"api-key\": this.azureOpenAIApiKey,\n      ...requestOptions.headers,\n    };\n    requestOptions.query = {\n      \"api-version\": this.azureOpenAIApiVersion,\n      ...requestOptions.query,\n    };\n  }\n  return requestOptions;\n}\n\nfunction _serializeAzureChat(\n  this: BaseChatOpenAI<ChatOpenAICallOptions> & Partial<AzureOpenAIChatInput>,\n  input: Serialized\n) {\n  const json = input;\n\n  function isRecord(obj: unknown): obj is Record<string, unknown> {\n    return typeof obj === \"object\" && obj != null;\n  }\n\n  if (isRecord(json) && isRecord(json.kwargs)) {\n    delete json.kwargs.azure_openai_base_path;\n    delete json.kwargs.azure_openai_api_deployment_name;\n    delete json.kwargs.azure_openai_api_key;\n    delete json.kwargs.azure_openai_api_version;\n    delete json.kwargs.azure_open_ai_base_path;\n\n    if (!json.kwargs.azure_endpoint && this.azureOpenAIEndpoint) {\n      json.kwargs.azure_endpoint = this.azureOpenAIEndpoint;\n    }\n    if (!json.kwargs.azure_endpoint && this.azureOpenAIBasePath) {\n      const parts = this.azureOpenAIBasePath.split(\"/openai/deployments/\");\n      if (parts.length === 2 && parts[0].startsWith(\"http\")) {\n        const [endpoint] = parts;\n        json.kwargs.azure_endpoint = endpoint;\n      }\n    }\n    if (!json.kwargs.azure_endpoint && this.azureOpenAIApiInstanceName) {\n      json.kwargs.azure_endpoint = `https://${this.azureOpenAIApiInstanceName}.openai.azure.com/`;\n    }\n    if (!json.kwargs.deployment_name && this.azureOpenAIApiDeploymentName) {\n      json.kwargs.deployment_name = this.azureOpenAIApiDeploymentName;\n    }\n    if (!json.kwargs.deployment_name && this.azureOpenAIBasePath) {\n      const parts = this.azureOpenAIBasePath.split(\"/openai/deployments/\");\n      if (parts.length === 2) {\n        const [, deployment] = parts;\n        json.kwargs.deployment_name = deployment;\n      }\n    }\n\n    if (\n      json.kwargs.azure_endpoint &&\n      json.kwargs.deployment_name &&\n      json.kwargs.openai_api_base\n    ) {\n      delete json.kwargs.openai_api_base;\n    }\n    if (\n      json.kwargs.azure_openai_api_instance_name &&\n      json.kwargs.azure_endpoint\n    ) {\n      delete json.kwargs.azure_openai_api_instance_name;\n    }\n  }\n\n  return json;\n}\n\ninterface AzureChatOpenAIFields\n  extends BaseChatOpenAIFields,\n    Partial<AzureOpenAIChatInput> {\n  /**\n   * Whether to use the responses API for all requests. If `false` the responses API will be used\n   * only when required in order to fulfill the request.\n   */\n  useResponsesApi?: boolean;\n}\n\nclass AzureChatOpenAIResponses<\n    CallOptions extends ChatOpenAIResponsesCallOptions = ChatOpenAIResponsesCallOptions\n  >\n  extends ChatOpenAIResponses<CallOptions>\n  implements Partial<AzureOpenAIChatInput>\n{\n  azureOpenAIApiVersion?: string;\n\n  azureOpenAIApiKey?: string;\n\n  azureADTokenProvider?: () => Promise<string>;\n\n  azureOpenAIApiInstanceName?: string;\n\n  azureOpenAIApiDeploymentName?: string;\n\n  azureOpenAIBasePath?: string;\n\n  azureOpenAIEndpoint?: string;\n\n  _llmType(): string {\n    return \"azure_openai\";\n  }\n\n  get lc_aliases(): Record<string, string> {\n    return {\n      ...super.lc_aliases,\n      ...AZURE_ALIASES,\n    };\n  }\n\n  get lc_secrets(): { [key: string]: string } | undefined {\n    return {\n      ...super.lc_secrets,\n      ...AZURE_SECRETS,\n    };\n  }\n\n  get lc_serializable_keys(): string[] {\n    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];\n  }\n\n  getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {\n    const params = super.getLsParams(options);\n    params.ls_provider = \"azure\";\n    return params;\n  }\n\n  constructor(fields?: AzureChatOpenAIFields) {\n    super(fields);\n    _constructAzureFields.call(this, fields);\n  }\n\n  override _getClientOptions(\n    options: OpenAICoreRequestOptions | undefined\n  ): OpenAICoreRequestOptions {\n    return _getAzureClientOptions.call(this, options);\n  }\n\n  override toJSON(): Serialized {\n    return _serializeAzureChat.call(this, super.toJSON());\n  }\n}\n\nclass AzureChatOpenAICompletions<\n    CallOptions extends ChatOpenAICompletionsCallOptions = ChatOpenAICompletionsCallOptions\n  >\n  extends ChatOpenAICompletions<CallOptions>\n  implements Partial<AzureOpenAIChatInput>\n{\n  azureOpenAIApiVersion?: string;\n\n  azureOpenAIApiKey?: string;\n\n  azureADTokenProvider?: () => Promise<string>;\n\n  azureOpenAIApiInstanceName?: string;\n\n  azureOpenAIApiDeploymentName?: string;\n\n  azureOpenAIBasePath?: string;\n\n  azureOpenAIEndpoint?: string;\n\n  _llmType(): string {\n    return \"azure_openai\";\n  }\n\n  get lc_aliases(): Record<string, string> {\n    return {\n      ...super.lc_aliases,\n      ...AZURE_ALIASES,\n    };\n  }\n\n  get lc_secrets(): { [key: string]: string } | undefined {\n    return {\n      ...super.lc_secrets,\n      ...AZURE_SECRETS,\n    };\n  }\n\n  get lc_serializable_keys(): string[] {\n    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];\n  }\n\n  getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {\n    const params = super.getLsParams(options);\n    params.ls_provider = \"azure\";\n    return params;\n  }\n\n  constructor(fields?: AzureChatOpenAIFields) {\n    super(fields);\n    _constructAzureFields.call(this, fields);\n  }\n\n  override _getClientOptions(\n    options: OpenAICoreRequestOptions | undefined\n  ): OpenAICoreRequestOptions {\n    return _getAzureClientOptions.call(this, options);\n  }\n\n  override toJSON(): Serialized {\n    return _serializeAzureChat.call(this, super.toJSON());\n  }\n}\n\n/**\n * Azure OpenAI chat model integration.\n *\n * Setup:\n * Install `@langchain/openai` and set the following environment variables:\n *\n * ```bash\n * npm install @langchain/openai\n * export AZURE_OPENAI_API_KEY=\"your-api-key\"\n * export AZURE_OPENAI_API_DEPLOYMENT_NAME=\"your-deployment-name\"\n * export AZURE_OPENAI_API_VERSION=\"your-version\"\n * export AZURE_OPENAI_BASE_PATH=\"your-base-path\"\n * ```\n *\n * ## [Constructor args](https://api.js.langchain.com/classes/langchain_openai.AzureChatOpenAI.html#constructor)\n *\n * ## [Runtime args](https://api.js.langchain.com/interfaces/langchain_openai.ChatOpenAICallOptions.html)\n *\n * Runtime args can be passed as the second argument to any of the base runnable methods `.invoke`. `.stream`, `.batch`, etc.\n * They can also be passed via `.withConfig`, or the second arg in `.bindTools`, like shown in the examples below:\n *\n * ```typescript\n * // When calling `.withConfig`, call options should be passed via the first argument\n * const llmWithArgsBound = llm.withConfig({\n *   stop: [\"\\n\"],\n *   tools: [...],\n * });\n *\n * // When calling `.bindTools`, call options should be passed via the second argument\n * const llmWithTools = llm.bindTools(\n *   [...],\n *   {\n *     tool_choice: \"auto\",\n *   }\n * );\n * ```\n *\n * ## Examples\n *\n * <details open>\n * <summary><strong>Instantiate</strong></summary>\n *\n * ```typescript\n * import { AzureChatOpenAI } from '@langchain/openai';\n *\n * const llm = new AzureChatOpenAI({\n *   azureOpenAIApiKey: process.env.AZURE_OPENAI_API_KEY, // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY\n *   azureOpenAIApiInstanceName: process.env.AZURE_OPENAI_API_INSTANCE_NAME, // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME\n *   azureOpenAIApiDeploymentName: process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME, // In Node.js defaults to process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME\n *   azureOpenAIApiVersion: process.env.AZURE_OPENAI_API_VERSION, // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION\n *   temperature: 0,\n *   maxTokens: undefined,\n *   timeout: undefined,\n *   maxRetries: 2,\n *   // apiKey: \"...\",\n *   // baseUrl: \"...\",\n *   // other params...\n * });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Invoking</strong></summary>\n *\n * ```typescript\n * const input = `Translate \"I love programming\" into French.`;\n *\n * // Models also accept a list of chat messages or a formatted prompt\n * const result = await llm.invoke(input);\n * console.log(result);\n * ```\n *\n * ```txt\n * AIMessage {\n *   \"id\": \"chatcmpl-9u4Mpu44CbPjwYFkTbeoZgvzB00Tz\",\n *   \"content\": \"J'adore la programmation.\",\n *   \"response_metadata\": {\n *     \"tokenUsage\": {\n *       \"completionTokens\": 5,\n *       \"promptTokens\": 28,\n *       \"totalTokens\": 33\n *     },\n *     \"finish_reason\": \"stop\",\n *     \"system_fingerprint\": \"fp_3aa7262c27\"\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 28,\n *     \"output_tokens\": 5,\n *     \"total_tokens\": 33\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Streaming Chunks</strong></summary>\n *\n * ```typescript\n * for await (const chunk of await llm.stream(input)) {\n *   console.log(chunk);\n * }\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"id\": \"chatcmpl-9u4NWB7yUeHCKdLr6jP3HpaOYHTqs\",\n *   \"content\": \"\"\n * }\n * AIMessageChunk {\n *   \"content\": \"J\"\n * }\n * AIMessageChunk {\n *   \"content\": \"'adore\"\n * }\n * AIMessageChunk {\n *   \"content\": \" la\"\n * }\n * AIMessageChunk {\n *   \"content\": \" programmation\",,\n * }\n * AIMessageChunk {\n *   \"content\": \".\",,\n * }\n * AIMessageChunk {\n *   \"content\": \"\",\n *   \"response_metadata\": {\n *     \"finish_reason\": \"stop\",\n *     \"system_fingerprint\": \"fp_c9aa9c0491\"\n *   },\n * }\n * AIMessageChunk {\n *   \"content\": \"\",\n *   \"usage_metadata\": {\n *     \"input_tokens\": 28,\n *     \"output_tokens\": 5,\n *     \"total_tokens\": 33\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Aggregate Streamed Chunks</strong></summary>\n *\n * ```typescript\n * import { AIMessageChunk } from '@langchain/core/messages';\n * import { concat } from '@langchain/core/utils/stream';\n *\n * const stream = await llm.stream(input);\n * let full: AIMessageChunk | undefined;\n * for await (const chunk of stream) {\n *   full = !full ? chunk : concat(full, chunk);\n * }\n * console.log(full);\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"id\": \"chatcmpl-9u4PnX6Fy7OmK46DASy0bH6cxn5Xu\",\n *   \"content\": \"J'adore la programmation.\",\n *   \"response_metadata\": {\n *     \"prompt\": 0,\n *     \"completion\": 0,\n *     \"finish_reason\": \"stop\",\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 28,\n *     \"output_tokens\": 5,\n *     \"total_tokens\": 33\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Bind tools</strong></summary>\n *\n * ```typescript\n * import { z } from 'zod';\n *\n * const GetWeather = {\n *   name: \"GetWeather\",\n *   description: \"Get the current weather in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const GetPopulation = {\n *   name: \"GetPopulation\",\n *   description: \"Get the current population in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const llmWithTools = llm.bindTools([GetWeather, GetPopulation]);\n * const aiMsg = await llmWithTools.invoke(\n *   \"Which city is hotter today and which is bigger: LA or NY?\"\n * );\n * console.log(aiMsg.tool_calls);\n * ```\n *\n * ```txt\n * [\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call',\n *     id: 'call_uPU4FiFzoKAtMxfmPnfQL6UK'\n *   },\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call',\n *     id: 'call_UNkEwuQsHrGYqgDQuH9nPAtX'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call',\n *     id: 'call_kL3OXxaq9OjIKqRTpvjaCH14'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call',\n *     id: 'call_s9KQB1UWj45LLGaEnjz0179q'\n *   }\n * ]\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Structured Output</strong></summary>\n *\n * ```typescript\n * import { z } from 'zod';\n *\n * const Joke = z.object({\n *   setup: z.string().describe(\"The setup of the joke\"),\n *   punchline: z.string().describe(\"The punchline to the joke\"),\n *   rating: z.number().nullable().describe(\"How funny the joke is, from 1 to 10\")\n * }).describe('Joke to tell user.');\n *\n * const structuredLlm = llm.withStructuredOutput(Joke, { name: \"Joke\" });\n * const jokeResult = await structuredLlm.invoke(\"Tell me a joke about cats\");\n * console.log(jokeResult);\n * ```\n *\n * ```txt\n * {\n *   setup: 'Why was the cat sitting on the computer?',\n *   punchline: 'Because it wanted to keep an eye on the mouse!',\n *   rating: 7\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>JSON Object Response Format</strong></summary>\n *\n * ```typescript\n * const jsonLlm = llm.withConfig({ response_format: { type: \"json_object\" } });\n * const jsonLlmAiMsg = await jsonLlm.invoke(\n *   \"Return a JSON object with key 'randomInts' and a value of 10 random ints in [0-99]\"\n * );\n * console.log(jsonLlmAiMsg.content);\n * ```\n *\n * ```txt\n * {\n *   \"randomInts\": [23, 87, 45, 12, 78, 34, 56, 90, 11, 67]\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Multimodal</strong></summary>\n *\n * ```typescript\n * import { HumanMessage } from '@langchain/core/messages';\n *\n * const imageUrl = \"https://example.com/image.jpg\";\n * const imageData = await fetch(imageUrl).then(res => res.arrayBuffer());\n * const base64Image = Buffer.from(imageData).toString('base64');\n *\n * const message = new HumanMessage({\n *   content: [\n *     { type: \"text\", text: \"describe the weather in this image\" },\n *     {\n *       type: \"image_url\",\n *       image_url: { url: `data:image/jpeg;base64,${base64Image}` },\n *     },\n *   ]\n * });\n *\n * const imageDescriptionAiMsg = await llm.invoke([message]);\n * console.log(imageDescriptionAiMsg.content);\n * ```\n *\n * ```txt\n * The weather in the image appears to be clear and sunny. The sky is mostly blue with a few scattered white clouds, indicating fair weather. The bright sunlight is casting shadows on the green, grassy hill, suggesting it is a pleasant day with good visibility. There are no signs of rain or stormy conditions.\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Usage Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForMetadata = await llm.invoke(input);\n * console.log(aiMsgForMetadata.usage_metadata);\n * ```\n *\n * ```txt\n * { input_tokens: 28, output_tokens: 5, total_tokens: 33 }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Logprobs</strong></summary>\n *\n * ```typescript\n * const logprobsLlm = new ChatOpenAI({ model: \"gpt-4o-mini\", logprobs: true });\n * const aiMsgForLogprobs = await logprobsLlm.invoke(input);\n * console.log(aiMsgForLogprobs.response_metadata.logprobs);\n * ```\n *\n * ```txt\n * {\n *   content: [\n *     {\n *       token: 'J',\n *       logprob: -0.000050616763,\n *       bytes: [Array],\n *       top_logprobs: []\n *     },\n *     {\n *       token: \"'\",\n *       logprob: -0.01868736,\n *       bytes: [Array],\n *       top_logprobs: []\n *     },\n *     {\n *       token: 'ad',\n *       logprob: -0.0000030545007,\n *       bytes: [Array],\n *       top_logprobs: []\n *     },\n *     { token: 'ore', logprob: 0, bytes: [Array], top_logprobs: [] },\n *     {\n *       token: ' la',\n *       logprob: -0.515404,\n *       bytes: [Array],\n *       top_logprobs: []\n *     },\n *     {\n *       token: ' programm',\n *       logprob: -0.0000118755715,\n *       bytes: [Array],\n *       top_logprobs: []\n *     },\n *     { token: 'ation', logprob: 0, bytes: [Array], top_logprobs: [] },\n *     {\n *       token: '.',\n *       logprob: -0.0000037697225,\n *       bytes: [Array],\n *       top_logprobs: []\n *     }\n *   ],\n *   refusal: null\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Response Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForResponseMetadata = await llm.invoke(input);\n * console.log(aiMsgForResponseMetadata.response_metadata);\n * ```\n *\n * ```txt\n * {\n *   tokenUsage: { completionTokens: 5, promptTokens: 28, totalTokens: 33 },\n *   finish_reason: 'stop',\n *   system_fingerprint: 'fp_3aa7262c27'\n * }\n * ```\n * </details>\n */\nexport class AzureChatOpenAI<\n    CallOptions extends ChatOpenAICallOptions = ChatOpenAICallOptions\n  >\n  extends ChatOpenAI<CallOptions>\n  implements Partial<AzureOpenAIChatInput>\n{\n  azureOpenAIApiVersion?: string;\n\n  azureOpenAIApiKey?: string;\n\n  azureADTokenProvider?: () => Promise<string>;\n\n  azureOpenAIApiInstanceName?: string;\n\n  azureOpenAIApiDeploymentName?: string;\n\n  azureOpenAIBasePath?: string;\n\n  azureOpenAIEndpoint?: string;\n\n  _llmType(): string {\n    return \"azure_openai\";\n  }\n\n  get lc_aliases(): Record<string, string> {\n    return {\n      ...super.lc_aliases,\n      ...AZURE_ALIASES,\n    };\n  }\n\n  get lc_secrets(): { [key: string]: string } | undefined {\n    return {\n      ...super.lc_secrets,\n      ...AZURE_SECRETS,\n    };\n  }\n\n  get lc_serializable_keys(): string[] {\n    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];\n  }\n\n  getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {\n    const params = super.getLsParams(options);\n    params.ls_provider = \"azure\";\n    return params;\n  }\n\n  constructor(fields?: AzureChatOpenAIFields) {\n    super({\n      ...fields,\n      completions: new AzureChatOpenAICompletions(fields),\n      responses: new AzureChatOpenAIResponses(fields),\n    });\n    _constructAzureFields.call(this, fields);\n  }\n\n  /** @internal */\n  override _getStructuredOutputMethod(\n    config: StructuredOutputMethodOptions<boolean>\n  ) {\n    const ensuredConfig = { ...config };\n    // Not all Azure gpt-4o deployments models support jsonSchema yet\n    if (this.model.startsWith(\"gpt-4o\")) {\n      if (ensuredConfig?.method === undefined) {\n        return \"functionCalling\";\n      }\n    }\n    return super._getStructuredOutputMethod(ensuredConfig);\n  }\n\n  override toJSON(): Serialized {\n    return _serializeAzureChat.call(this, super.toJSON());\n  }\n}\n"],"mappings":";;;;;;AA4BA,MAAM,gBAAgB;CACpB,cAAc;CACd,kBAAkB;CAClB,gBAAgB;CAChB,gBAAgB;CAChB,qBAAqB;CACrB,uBAAuB;CACvB,qBAAqB;CACrB,8BAA8B;AAC/B;AAED,MAAM,gBAAgB,EACpB,mBAAmB,uBACpB;AAED,MAAM,0BAA0B;CAC9B;CACA;CACA;CACA;CACA;CACA;CACA;CACA;CACA;AACD;AAED,SAAS,sBAEPA,QACA;CACA,KAAK,oBACH,QAAQ,qBACR,QAAQ,gBACR,QAAQ,UACR,uBAAuB,uBAAuB;CAEhD,KAAK,6BACH,QAAQ,8BACR,uBAAuB,iCAAiC;CAE1D,KAAK,+BACH,QAAQ,gCACR,QAAQ,kBACR,uBAAuB,mCAAmC;CAE5D,KAAK,wBACH,QAAQ,yBACR,QAAQ,oBACR,uBAAuB,2BAA2B;CAEpD,KAAK,sBACH,QAAQ,uBACR,uBAAuB,yBAAyB;CAElD,KAAK,sBACH,QAAQ,uBACR,uBAAuB,wBAAwB;CAEjD,KAAK,uBAAuB,QAAQ;AAEpC,KAAI,CAAC,KAAK,qBAAqB,CAAC,KAAK,UAAU,CAAC,KAAK,qBACnD,OAAM,IAAI,MAAM;AAEnB;AAED,SAAS,uBAEPC,SACA;AACA,KAAI,CAAC,KAAK,QAAQ;EAChB,MAAMC,uBAA6C;GACjD,8BAA8B,KAAK;GACnC,4BAA4B,KAAK;GACjC,mBAAmB,KAAK;GACxB,qBAAqB,KAAK;GAC1B,sBAAsB,KAAK;GAC3B,SAAS,KAAK,aAAa;GAC3B,qBAAqB,KAAK;EAC3B;EAED,MAAM,WAAW,YAAY,qBAAqB;EAElD,MAAM,SAAS;GACb,GAAG,KAAK;GACR,SAAS;GACT,SAAS,KAAK;GACd,YAAY;EACb;AAED,MAAI,CAAC,KAAK,sBACR,OAAO,SAAS,qBAAqB;AAGvC,MAAI,CAAC,OAAO,SACV,OAAO,OAAO;EAGhB,IAAI,MAAM,QAAQ;AAClB,MAAI,QAAQ,UAAU,QAAQ,QAC5B,MAAM,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,QAAQ,QAAQ,EAAE,EAAE,QAAQ,SAAS,EAAE,EAAE,QAAQ,KAAK,CAAC,CAAC;EAG3E,MAAM,iBAAiB,iBAAiB,OAAO,eAAe;EAC9D,OAAO,iBAAiB;GACtB,GAAG,OAAO;GACV,cAAc,eAAe,gBACzB,CAAC,gCAAgC,EAAE,IAAI,CAAC,EAAE,eAAe,eAAe,GACxE,CAAC,gCAAgC,EAAE,IAAI,CAAC,CAAC;EAC9C;EAED,KAAK,SAAS,IAAIC,YAAkB;GAClC,YAAY,KAAK;GACjB,sBAAsB,KAAK;GAC3B,YAAY,KAAK;GACjB,GAAG;EACJ;CACF;CACD,MAAM,iBAAiB;EACrB,GAAG,KAAK;EACR,GAAG;CACJ;AACD,KAAI,KAAK,mBAAmB;EAC1B,eAAe,UAAU;GACvB,WAAW,KAAK;GAChB,GAAG,eAAe;EACnB;EACD,eAAe,QAAQ;GACrB,eAAe,KAAK;GACpB,GAAG,eAAe;EACnB;CACF;AACD,QAAO;AACR;AAED,SAAS,oBAEPC,OACA;CACA,MAAM,OAAO;CAEb,SAAS,SAASC,KAA8C;AAC9D,SAAO,OAAO,QAAQ,YAAY,OAAO;CAC1C;AAED,KAAI,SAAS,KAAK,IAAI,SAAS,KAAK,OAAO,EAAE;EAC3C,OAAO,KAAK,OAAO;EACnB,OAAO,KAAK,OAAO;EACnB,OAAO,KAAK,OAAO;EACnB,OAAO,KAAK,OAAO;EACnB,OAAO,KAAK,OAAO;AAEnB,MAAI,CAAC,KAAK,OAAO,kBAAkB,KAAK,qBACtC,KAAK,OAAO,iBAAiB,KAAK;AAEpC,MAAI,CAAC,KAAK,OAAO,kBAAkB,KAAK,qBAAqB;GAC3D,MAAM,QAAQ,KAAK,oBAAoB,MAAM,uBAAuB;AACpE,OAAI,MAAM,WAAW,KAAK,MAAM,GAAG,WAAW,OAAO,EAAE;IACrD,MAAM,CAAC,SAAS,GAAG;IACnB,KAAK,OAAO,iBAAiB;GAC9B;EACF;AACD,MAAI,CAAC,KAAK,OAAO,kBAAkB,KAAK,4BACtC,KAAK,OAAO,iBAAiB,CAAC,QAAQ,EAAE,KAAK,2BAA2B,kBAAkB,CAAC;AAE7F,MAAI,CAAC,KAAK,OAAO,mBAAmB,KAAK,8BACvC,KAAK,OAAO,kBAAkB,KAAK;AAErC,MAAI,CAAC,KAAK,OAAO,mBAAmB,KAAK,qBAAqB;GAC5D,MAAM,QAAQ,KAAK,oBAAoB,MAAM,uBAAuB;AACpE,OAAI,MAAM,WAAW,GAAG;IACtB,MAAM,GAAG,WAAW,GAAG;IACvB,KAAK,OAAO,kBAAkB;GAC/B;EACF;AAED,MACE,KAAK,OAAO,kBACZ,KAAK,OAAO,mBACZ,KAAK,OAAO,iBAEZ,OAAO,KAAK,OAAO;AAErB,MACE,KAAK,OAAO,kCACZ,KAAK,OAAO,gBAEZ,OAAO,KAAK,OAAO;CAEtB;AAED,QAAO;AACR;AAYD,IAAM,2BAAN,cAGU,oBAEV;CACE;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,WAAmB;AACjB,SAAO;CACR;CAED,IAAI,aAAqC;AACvC,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,aAAoD;AACtD,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,uBAAiC;AACnC,SAAO,CAAC,GAAG,MAAM,sBAAsB,GAAG,uBAAwB;CACnE;CAED,YAAYC,SAAqD;EAC/D,MAAM,SAAS,MAAM,YAAY,QAAQ;EACzC,OAAO,cAAc;AACrB,SAAO;CACR;CAED,YAAYN,QAAgC;EAC1C,MAAM,OAAO;EACb,sBAAsB,KAAK,MAAM,OAAO;CACzC;CAED,AAAS,kBACPC,SAC0B;AAC1B,SAAO,uBAAuB,KAAK,MAAM,QAAQ;CAClD;CAED,AAAS,SAAqB;AAC5B,SAAO,oBAAoB,KAAK,MAAM,MAAM,QAAQ,CAAC;CACtD;AACF;AAED,IAAM,6BAAN,cAGU,sBAEV;CACE;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,WAAmB;AACjB,SAAO;CACR;CAED,IAAI,aAAqC;AACvC,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,aAAoD;AACtD,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,uBAAiC;AACnC,SAAO,CAAC,GAAG,MAAM,sBAAsB,GAAG,uBAAwB;CACnE;CAED,YAAYK,SAAqD;EAC/D,MAAM,SAAS,MAAM,YAAY,QAAQ;EACzC,OAAO,cAAc;AACrB,SAAO;CACR;CAED,YAAYN,QAAgC;EAC1C,MAAM,OAAO;EACb,sBAAsB,KAAK,MAAM,OAAO;CACzC;CAED,AAAS,kBACPC,SAC0B;AAC1B,SAAO,uBAAuB,KAAK,MAAM,QAAQ;CAClD;CAED,AAAS,SAAqB;AAC5B,SAAO,oBAAoB,KAAK,MAAM,MAAM,QAAQ,CAAC;CACtD;AACF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8ZD,IAAa,kBAAb,cAGU,WAEV;CACE;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,WAAmB;AACjB,SAAO;CACR;CAED,IAAI,aAAqC;AACvC,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,aAAoD;AACtD,SAAO;GACL,GAAG,MAAM;GACT,GAAG;EACJ;CACF;CAED,IAAI,uBAAiC;AACnC,SAAO,CAAC,GAAG,MAAM,sBAAsB,GAAG,uBAAwB;CACnE;CAED,YAAYK,SAAqD;EAC/D,MAAM,SAAS,MAAM,YAAY,QAAQ;EACzC,OAAO,cAAc;AACrB,SAAO;CACR;CAED,YAAYN,QAAgC;EAC1C,MAAM;GACJ,GAAG;GACH,aAAa,IAAI,2BAA2B;GAC5C,WAAW,IAAI,yBAAyB;EACzC,EAAC;EACF,sBAAsB,KAAK,MAAM,OAAO;CACzC;;CAGD,AAAS,2BACPO,QACA;EACA,MAAM,gBAAgB,EAAE,GAAG,OAAQ;AAEnC,MAAI,KAAK,MAAM,WAAW,SAAS,EACjC;OAAI,eAAe,WAAW,OAC5B,QAAO;EACR;AAEH,SAAO,MAAM,2BAA2B,cAAc;CACvD;CAED,AAAS,SAAqB;AAC5B,SAAO,oBAAoB,KAAK,MAAM,MAAM,QAAQ,CAAC;CACtD;AACF"}