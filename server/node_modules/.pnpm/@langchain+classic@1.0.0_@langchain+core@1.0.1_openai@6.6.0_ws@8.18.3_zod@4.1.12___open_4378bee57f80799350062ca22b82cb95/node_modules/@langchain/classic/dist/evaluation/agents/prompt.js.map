{"version":3,"file":"prompt.js","names":[],"sources":["../../../src/evaluation/agents/prompt.ts"],"sourcesContent":["/**\n * Prompt for trajectory evaluation chain.\n */\n\nimport {\n  AIMessagePromptTemplate,\n  ChatPromptTemplate,\n  HumanMessagePromptTemplate,\n  SystemMessagePromptTemplate,\n} from \"@langchain/core/prompts\";\n\nconst EVAL_TEMPLATE = `An AI language model has been given access to the following set of tools to help answer a user's question.\n\nThe tools given to the AI model are:\n[TOOL_DESCRIPTIONS]\n{toolDescriptions}\n[END_TOOL_DESCRIPTIONS]\n\nThe question the human asked the AI model was:\n[QUESTION]\n{question}\n[END_QUESTION]{reference}\n\nThe AI language model decided to use the following set of tools to answer the question:\n[AGENT_TRAJECTORY]\n{agentTrajectory}\n[END_AGENT_TRAJECTORY]\n\nThe AI language model's final answer to the question was:\n[RESPONSE]\n{answer}\n[END_RESPONSE]\n\nLet's do a detailed evaluation of the AI language model's answer step by step.\n\nWe consider the following criteria before giving a score from 1 to 5:\n\ni. Is the final answer helpful?\nii. Does the AI language use a logical sequence of tools to answer the question?\niii. Does the AI language model use the tools in a helpful way?\niv. Does the AI language model use too many steps to answer the question?\nv. Are the appropriate tools used to answer the question?`;\n\nconst EXAMPLE_INPUT = `An AI language model has been given access to the following set of tools to help answer a user's question.\n\nThe tools given to the AI model are:\n[TOOL_DESCRIPTIONS]\nTool 1:\nName: Search\nDescription: useful for when you need to ask with search\n\nTool 2:\nName: Lookup\nDescription: useful for when you need to ask with lookup\n\nTool 3:\nName: Calculator\nDescription: useful for doing calculations\n\nTool 4:\nName: Search the Web (SerpAPI)\nDescription: useful for when you need to answer questions about current events\n[END_TOOL_DESCRIPTIONS]\n\nThe question the human asked the AI model was: If laid the Statue of Liberty end to end, how many times would it stretch across the United States?\n\n    The AI language model decided to use the following set of tools to answer the question:\n[AGENT_TRAJECTORY]\nStep 1:\nTool used: Search the Web (SerpAPI)\nTool input: If laid the Statue of Liberty end to end, how many times would it stretch across the United States?\nTool output: The Statue of Liberty was given to the United States by France, as a symbol of the two countries' friendship. It was erected atop an American-designed ...\n[END_AGENT_TRAJECTORY]\n\n[RESPONSE]\nThe AI language model's final answer to the question was: There are different ways to measure the length of the United States, but if we use the distance between the Statue of Liberty and the westernmost point of the contiguous United States (Cape Alava, Washington), which is approximately 2,857 miles (4,596 km), and assume that the Statue of Liberty is 305 feet (93 meters) tall, then the statue would stretch across the United States approximately 17.5 times if laid end to end.\n[END_RESPONSE]\n\nLet's do a detailed evaluation of the AI language model's answer step by step.\n\nWe consider the following criteria before giving a score from 1 to 5:\n\ni. Is the final answer helpful?\nii. Does the AI language use a logical sequence of tools to answer the question?\niii. Does the AI language model use the tools in a helpful way?\niv. Does the AI language model use too many steps to answer the question?\nv. Are the appropriate tools used to answer the question?`;\n\nconst EXAMPLE_OUTPUT = `First, let's evaluate the final answer. The final uses good reasoning but is wrong. 2,857 divided by 305 is not 17.5.\\\nThe model should have used the calculator to figure this out. Second does the model use a logical sequence of tools to answer the question?\\\nThe way model uses the search is not helpful. The model should have used the search tool to figure the width of the US or the height of the statue.\\\nThe model didn't use the calculator tool and gave an incorrect answer. The search API should be used for current events or specific questions.\\\nThe tools were not used in a helpful way. The model did not use too many steps to answer the question.\\\nThe model did not use the appropriate tools to answer the question.\\\n\nJudgment: Given the good reasoning in the final answer but otherwise poor performance, we give the model a score of 2.\n\nScore: 2`;\n\nexport const EVAL_CHAT_PROMPT = /* #__PURE__ */ ChatPromptTemplate.fromMessages(\n  [\n    /* #__PURE__ */ SystemMessagePromptTemplate.fromTemplate(\n      \"You are a helpful assistant that evaluates language models.\"\n    ),\n    /* #__PURE__ */ HumanMessagePromptTemplate.fromTemplate(EXAMPLE_INPUT),\n    /* #__PURE__ */ AIMessagePromptTemplate.fromTemplate(EXAMPLE_OUTPUT),\n    /* #__PURE__ */ HumanMessagePromptTemplate.fromTemplate(EVAL_TEMPLATE),\n  ]\n);\n\nconst TOOL_FREE_EVAL_TEMPLATE = `An AI language model has been given access to a set of tools to help answer a user's question.\n\nThe question the human asked the AI model was:\n[QUESTION]\n{question}\n[END_QUESTION]{reference}\n\nThe AI language model decided to use the following set of tools to answer the question:\n[AGENT_TRAJECTORY]\n{agentTrajectory}\n[END_AGENT_TRAJECTORY]\n\nThe AI language model's final answer to the question was:\n[RESPONSE]\n{answer}\n[END_RESPONSE]\n\nLet's do a detailed evaluation of the AI language model's answer step by step.\n\nWe consider the following criteria before giving a score from 1 to 5:\n\ni. Is the final answer helpful?\n    ii. Does the AI language use a logical sequence of tools to answer the question?\n    iii. Does the AI language model use the tools in a helpful way?\n    iv. Does the AI language model use too many steps to answer the question?\n    v. Are the appropriate tools used to answer the question?`;\n\nexport const TOOL_FREE_EVAL_CHAT_PROMPT =\n  /* #__PURE__ */ ChatPromptTemplate.fromMessages([\n    /* #__PURE__ */ SystemMessagePromptTemplate.fromTemplate(\n      \"You are a helpful assistant that evaluates language models.\"\n    ),\n    /* #__PURE__ */ HumanMessagePromptTemplate.fromTemplate(EXAMPLE_INPUT),\n    /* #__PURE__ */ AIMessagePromptTemplate.fromTemplate(EXAMPLE_OUTPUT),\n    /* #__PURE__ */ HumanMessagePromptTemplate.fromTemplate(\n      TOOL_FREE_EVAL_TEMPLATE\n    ),\n  ]);\n"],"mappings":";;;AAWA,MAAM,gBAAgB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;yDA8BkC,CAAC;AAE1D,MAAM,gBAAgB,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;yDA2CkC,CAAC;AAE1D,MAAM,iBAAiB,CAAC;;;;;;;;;QAShB,CAAC;AAET,MAAa,mCAAmC,mBAAmB,aACjE;iBACkB,4BAA4B,aAC1C,8DACD;iBACe,2BAA2B,aAAa,cAAc;iBACtD,wBAAwB,aAAa,eAAe;iBACpD,2BAA2B,aAAa,cAAc;AACvE,EACF;AAED,MAAM,0BAA0B,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;6DAyB4B,CAAC;AAE9D,MAAa,6CACK,mBAAmB,aAAa;iBAC9B,4BAA4B,aAC1C,8DACD;iBACe,2BAA2B,aAAa,cAAc;iBACtD,wBAAwB,aAAa,eAAe;iBACpD,2BAA2B,aACzC,wBACD;AACF,EAAC"}