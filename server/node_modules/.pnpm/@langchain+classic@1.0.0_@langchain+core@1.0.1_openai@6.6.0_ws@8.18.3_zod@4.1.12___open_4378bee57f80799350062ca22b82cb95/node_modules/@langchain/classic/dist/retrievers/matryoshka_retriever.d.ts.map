{"version":3,"file":"matryoshka_retriever.d.ts","names":["DocumentInterface","Embeddings","VectorStore","VectorStoreRetriever","VectorStoreRetrieverInput","AddDocumentOptions","Record","MatryoshkaRetrieverFields","MatryoshkaRetriever","Store","Promise"],"sources":["../../src/retrievers/matryoshka_retriever.d.ts"],"sourcesContent":["import { DocumentInterface } from \"@langchain/core/documents\";\nimport { Embeddings } from \"@langchain/core/embeddings\";\nimport { VectorStore, VectorStoreRetriever, VectorStoreRetrieverInput } from \"@langchain/core/vectorstores\";\n/**\n * Type for options when adding a document to the VectorStore.\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ntype AddDocumentOptions = Record<string, any>;\nexport interface MatryoshkaRetrieverFields {\n    /**\n     * The number of documents to retrieve from the small store.\n     * @default 50\n     */\n    smallK?: number;\n    /**\n     * The number of documents to retrieve from the large store.\n     * @default 8\n     */\n    largeK?: number;\n    /**\n     * The metadata key to store the larger embeddings.\n     * @default \"lc_large_embedding\"\n     */\n    largeEmbeddingKey?: string;\n    /**\n     * The embedding model to use when generating the large\n     * embeddings.\n     */\n    largeEmbeddingModel: Embeddings;\n    /**\n     * The type of search to perform using the large embeddings.\n     * @default \"cosine\"\n     */\n    searchType?: \"cosine\" | \"innerProduct\" | \"euclidean\";\n}\n/**\n * A retriever that uses two sets of embeddings to perform adaptive retrieval. Based\n * off of the \"Matryoshka embeddings: faster OpenAI vector search using Adaptive Retrieval\"\n * blog post {@link https://supabase.com/blog/matryoshka-embeddings}.\n *\n *\n * This class performs \"Adaptive Retrieval\" for searching text embeddings efficiently using the\n * Matryoshka Representation Learning (MRL) technique. It retrieves documents similar to a query\n * embedding in two steps:\n *\n * First-pass: Uses a lower dimensional sub-vector from the MRL embedding for an initial, fast,\n * but less accurate search.\n *\n * Second-pass: Re-ranks the top results from the first pass using the full, high-dimensional\n * embedding for higher accuracy.\n *\n *\n * This code implements MRL embeddings for efficient vector search by combining faster,\n * lower-dimensional initial search with accurate, high-dimensional re-ranking.\n */\nexport declare class MatryoshkaRetriever<Store extends VectorStore = VectorStore> extends VectorStoreRetriever<Store> {\n    smallK: number;\n    largeK: number;\n    largeEmbeddingKey: string;\n    largeEmbeddingModel: Embeddings;\n    searchType: \"cosine\" | \"innerProduct\" | \"euclidean\";\n    constructor(fields: MatryoshkaRetrieverFields & VectorStoreRetrieverInput<Store>);\n    /**\n     * Ranks documents based on their similarity to a query embedding using larger embeddings.\n     *\n     * This method takes a query embedding and a list of documents (smallResults) as input. Each document\n     * in the smallResults array has previously been associated with a large embedding stored in its metadata.\n     * Depending on the `searchType` (cosine, innerProduct, or euclidean), it calculates the similarity scores\n     * between the query embedding and each document's large embedding. It then ranks the documents based on\n     * these similarity scores, from the most similar to the least similar.\n     *\n     * The method returns a promise that resolves to an array of the top `largeK` documents, where `largeK`\n     * is a class property defining the number of documents to return. This subset of documents is determined\n     * by sorting the entire list of documents based on their similarity scores and then selecting the top\n     * `largeK` documents.\n     *\n     * @param {number[]} embeddedQuery The embedding of the query, represented as an array of numbers.\n     * @param {DocumentInterface[]} smallResults An array of documents, each with metadata that includes a large embedding for similarity comparison.\n     * @returns {Promise<DocumentInterface[]>} A promise that resolves to an array of the top `largeK` ranked documents based on their similarity to the query embedding.\n     */\n    private _rankByLargeEmbeddings;\n    _getRelevantDocuments(query: string): Promise<DocumentInterface[]>;\n    /**\n     * Override the default `addDocuments` method to embed the documents twice,\n     * once using the larger embeddings model, and then again using the default\n     * embedding model linked to the vector store.\n     *\n     * @param {DocumentInterface[]} documents - An array of documents to add to the vector store.\n     * @param {AddDocumentOptions} options - An optional object containing additional options for adding documents.\n     * @returns {Promise<string[] | void>} A promise that resolves to an array of the document IDs that were added to the vector store.\n     */\n    addDocuments: (documents: DocumentInterface<Record<string, any>>[], options?: AddDocumentOptions | undefined) => Promise<void | string[]>;\n}\nexport {};\n"],"mappings":";;;;;;;;AAE4G;AAM5G;AA+CA,KAhDKK,kBAAAA,GAAqBC,MAgDc,CAAA,MAAA,EAAA,GAAA,CAAA;AAAA,UA/CvBC,yBAAAA,CA+CuB;EAAA;;;;EAIL,MAEXA,CAAAA,EAAAA,MAAAA;EAAyB;;;;EAoBA,MAUDD,CAAAA,EAAAA,MAAAA;EAAM;;;;EApCwD,iBAAA,CAAA,EAAA,MAAA;;;;;uBA3BrFL;;;;;;;;;;;;;;;;;;;;;;;;;;;cA2BJO,kCAAkCN,cAAcA,qBAAqBC,qBAAqBM;;;;uBAItFR;;sBAEDM,4BAA4BH,0BAA0BK;;;;;;;;;;;;;;;;;;;;wCAoBpCC,QAAQV;;;;;;;;;;4BAUpBA,kBAAkBM,kCAAkCD,mCAAmCK"}