{"version":3,"file":"token_buffer_memory.d.cts","names":["ChatOpenAI","InputValues","MemoryVariables","OutputValues","BaseChatMemory","BaseChatMemoryInput","OpenAIAgentTokenBufferMemoryFields","OpenAIAgentTokenBufferMemory","_langchain_core_messages0","MessageStructure","MessageType","BaseMessage","Promise"],"sources":["../../../../src/agents/toolkits/conversational_retrieval/token_buffer_memory.d.ts"],"sourcesContent":["import { ChatOpenAI } from \"@langchain/openai\";\nimport { InputValues, MemoryVariables, OutputValues } from \"@langchain/core/memory\";\nimport { BaseChatMemory, BaseChatMemoryInput } from \"../../../memory/chat_memory.js\";\n/**\n * Type definition for the fields required to initialize an instance of\n * OpenAIAgentTokenBufferMemory.\n */\nexport type OpenAIAgentTokenBufferMemoryFields = BaseChatMemoryInput & {\n    llm: ChatOpenAI;\n    humanPrefix?: string;\n    aiPrefix?: string;\n    memoryKey?: string;\n    maxTokenLimit?: number;\n    returnMessages?: boolean;\n    outputKey?: string;\n    intermediateStepsKey?: string;\n};\n/**\n * Memory used to save agent output and intermediate steps.\n */\nexport declare class OpenAIAgentTokenBufferMemory extends BaseChatMemory {\n    humanPrefix: string;\n    aiPrefix: string;\n    llm: ChatOpenAI;\n    memoryKey: string;\n    maxTokenLimit: number;\n    returnMessages: boolean;\n    outputKey: string;\n    intermediateStepsKey: string;\n    constructor(fields: OpenAIAgentTokenBufferMemoryFields);\n    get memoryKeys(): string[];\n    /**\n     * Retrieves the messages from the chat history.\n     * @returns Promise that resolves with the messages from the chat history.\n     */\n    getMessages(): Promise<import(\"@langchain/core/messages\").BaseMessage<import(\"@langchain/core/messages\").MessageStructure, import(\"@langchain/core/messages\").MessageType>[]>;\n    /**\n     * Loads memory variables from the input values.\n     * @param _values Input values.\n     * @returns Promise that resolves with the loaded memory variables.\n     */\n    loadMemoryVariables(_values: InputValues): Promise<MemoryVariables>;\n    /**\n     * Saves the context of the chat, including user input, AI output, and\n     * intermediate steps. Prunes the chat history if the total token count\n     * exceeds the maximum limit.\n     * @param inputValues Input values.\n     * @param outputValues Output values.\n     * @returns Promise that resolves when the context has been saved.\n     */\n    saveContext(inputValues: InputValues, outputValues: OutputValues): Promise<void>;\n}\n"],"mappings":";;;;;;;;;;AAOA;AAA8C,KAAlCM,kCAAAA,GAAqCD,mBAAH,GAAA;EAAA,GAAGA,EACxCL,UADwCK;EAAmB,WAC3DL,CAAAA,EAAAA,MAAAA;EAAU,QAAA,CAAA,EAAA,MAAA;EAYEO,SAAAA,CAAAA,EAAAA,MAAAA;EAA4B,aAAA,CAAA,EAAA,MAAA;EAAA,cAGxCP,CAAAA,EAAAA,OAAAA;EAAU,SAMKM,CAAAA,EAAAA,MAAAA;EAAkC,oBAAAE,CAAAA,EAAAA,MAMmDC;CAAgB;;;;AAMtEP,cArBlCK,4BAAAA,SAAqCH,cAAAA,CAqBHF;EAAe,WAAvBU,EAAAA,MAAAA;EAAO,QASzBX,EAAAA,MAAAA;EAAW,GAAgBE,EA3B/CH,UA2B+CG;EAAY,SAAGS,EAAAA,MAAAA;EAAO,aA9BpBR,EAAAA,MAAAA;EAAc,cAAA,EAAA,OAAA;;;sBAShDE;;;;;;iBAMLM,QAA0JJ,yBAAAA,CAA/GG,YANJH,yBAAAA,CAMmDC,gBAAAA,EAAgBD,yBAAAA,CAAqCE,WAAAA;;;;;;+BAMjIT,cAAcW,QAAQV;;;;;;;;;2BAS1BD,2BAA2BE,eAAeS"}