{"version":3,"file":"refine_prompts.js","names":[],"sources":["../../../src/chains/question_answering/refine_prompts.ts"],"sourcesContent":["import {\n  PromptTemplate,\n  ChatPromptTemplate,\n  SystemMessagePromptTemplate,\n  HumanMessagePromptTemplate,\n  AIMessagePromptTemplate,\n} from \"@langchain/core/prompts\";\nimport {\n  ConditionalPromptSelector,\n  isChatModel,\n} from \"@langchain/core/example_selectors\";\n\nexport const DEFAULT_REFINE_PROMPT_TMPL = `The original question is as follows: {question}\nWe have provided an existing answer: {existing_answer}\nWe have the opportunity to refine the existing answer\n(only if needed) with some more context below.\n------------\n{context}\n------------\nGiven the new context, refine the original answer to better answer the question. \nIf the context isn't useful, return the original answer.`;\nexport const DEFAULT_REFINE_PROMPT = /*#__PURE__*/ new PromptTemplate({\n  inputVariables: [\"question\", \"existing_answer\", \"context\"],\n  template: DEFAULT_REFINE_PROMPT_TMPL,\n});\n\nconst refineTemplate = `The original question is as follows: {question}\nWe have provided an existing answer: {existing_answer}\nWe have the opportunity to refine the existing answer\n(only if needed) with some more context below.\n------------\n{context}\n------------\nGiven the new context, refine the original answer to better answer the question. \nIf the context isn't useful, return the original answer.`;\n\nconst messages = [\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n  /*#__PURE__*/ AIMessagePromptTemplate.fromTemplate(\"{existing_answer}\"),\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(refineTemplate),\n];\n\nexport const CHAT_REFINE_PROMPT =\n  /*#__PURE__*/ ChatPromptTemplate.fromMessages(messages);\n\nexport const REFINE_PROMPT_SELECTOR =\n  /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_REFINE_PROMPT, [\n    [isChatModel, CHAT_REFINE_PROMPT],\n  ]);\n\nexport const DEFAULT_TEXT_QA_PROMPT_TMPL = `Context information is below. \n---------------------\n{context}\n---------------------\nGiven the context information and no prior knowledge, answer the question: {question}`;\nexport const DEFAULT_TEXT_QA_PROMPT = /*#__PURE__*/ new PromptTemplate({\n  inputVariables: [\"context\", \"question\"],\n  template: DEFAULT_TEXT_QA_PROMPT_TMPL,\n});\n\nconst chat_qa_prompt_template = `Context information is below. \n---------------------\n{context}\n---------------------\nGiven the context information and no prior knowledge, answer any questions`;\nconst chat_messages = [\n  /*#__PURE__*/ SystemMessagePromptTemplate.fromTemplate(\n    chat_qa_prompt_template\n  ),\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n];\nexport const CHAT_QUESTION_PROMPT =\n  /*#__PURE__*/ ChatPromptTemplate.fromMessages(chat_messages);\nexport const QUESTION_PROMPT_SELECTOR =\n  /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_TEXT_QA_PROMPT, [\n    [isChatModel, CHAT_QUESTION_PROMPT],\n  ]);\n"],"mappings":";;;;AAYA,MAAa,6BAA6B,CAAC;;;;;;;;wDAQa,CAAC;AACzD,MAAa,wCAAsC,IAAI,eAAe;CACpE,gBAAgB;EAAC;EAAY;EAAmB;CAAU;CAC1D,UAAU;AACX;AAED,MAAM,iBAAiB,CAAC;;;;;;;;wDAQgC,CAAC;AAEzD,MAAM,WAAW;iBACD,2BAA2B,aAAa,aAAa;iBACrD,wBAAwB,aAAa,oBAAoB;iBACzD,2BAA2B,aAAa,eAAe;AACtE;AAED,MAAa,qCACG,mBAAmB,aAAa,SAAS;AAEzD,MAAa,yCACG,IAAI,0BAA0B,uBAAuB,CACjE,CAAC,aAAa,kBAAmB,CAClC;AAEH,MAAa,8BAA8B,CAAC;;;;qFAIyC,CAAC;AACtF,MAAa,yCAAuC,IAAI,eAAe;CACrE,gBAAgB,CAAC,WAAW,UAAW;CACvC,UAAU;AACX;AAED,MAAM,0BAA0B,CAAC;;;;0EAIyC,CAAC;AAC3E,MAAM,gBAAgB,iBACN,4BAA4B,aACxC,wBACD,kBACa,2BAA2B,aAAa,aAAa,AACpE;AACD,MAAa,uCACG,mBAAmB,aAAa,cAAc;AAC9D,MAAa,2CACG,IAAI,0BAA0B,wBAAwB,CAClE,CAAC,aAAa,oBAAqB,CACpC"}