{"version":3,"file":"task_execution.cjs","names":["LLMChain","fields: Omit<LLMChainInput, \"prompt\">","PromptTemplate"],"sources":["../../../src/experimental/babyagi/task_execution.ts"],"sourcesContent":["import { PromptTemplate } from \"@langchain/core/prompts\";\nimport { LLMChain, LLMChainInput } from \"../../chains/llm_chain.js\";\n\n/** Chain to execute tasks. */\nexport class TaskExecutionChain extends LLMChain {\n  static lc_name() {\n    return \"TaskExecutionChain\";\n  }\n\n  /**\n   * A static factory method that creates an instance of TaskExecutionChain.\n   * It constructs a prompt template for task execution, which is then used\n   * to create a new instance of TaskExecutionChain. The prompt template\n   * instructs an AI to perform a task based on a given objective, taking\n   * into account previously completed tasks.\n   * @param fields An object of type LLMChainInput, excluding the \"prompt\" field.\n   * @returns An instance of LLMChain.\n   */\n  static fromLLM(fields: Omit<LLMChainInput, \"prompt\">): LLMChain {\n    const executionTemplate =\n      `You are an AI who performs one task based on the following objective: ` +\n      `{objective}.` +\n      `Take into account these previously completed tasks: {context}.` +\n      ` Your task: {task}. Response:`;\n    const prompt = new PromptTemplate({\n      template: executionTemplate,\n      inputVariables: [\"objective\", \"context\", \"task\"],\n    });\n    return new TaskExecutionChain({ prompt, ...fields });\n  }\n}\n"],"mappings":";;;;;;AAIA,IAAa,qBAAb,MAAa,2BAA2BA,2BAAS;CAC/C,OAAO,UAAU;AACf,SAAO;CACR;;;;;;;;;;CAWD,OAAO,QAAQC,QAAiD;EAC9D,MAAM,oBACJ;EAIF,MAAM,SAAS,IAAIC,wCAAe;GAChC,UAAU;GACV,gBAAgB;IAAC;IAAa;IAAW;GAAO;EACjD;AACD,SAAO,IAAI,mBAAmB;GAAE;GAAQ,GAAG;EAAQ;CACpD;AACF"}