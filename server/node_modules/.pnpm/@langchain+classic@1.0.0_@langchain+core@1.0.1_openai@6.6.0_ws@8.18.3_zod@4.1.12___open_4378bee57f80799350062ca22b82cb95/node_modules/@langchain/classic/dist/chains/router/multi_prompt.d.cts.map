{"version":3,"file":"multi_prompt.d.cts","names":["BaseLanguageModelInterface","PromptTemplate","MultiRouteChain","MultiRouteChainInput","BaseChain","LLMChainInput","MultiPromptChain","Omit","promptNames","promptDescriptions","promptTemplates","defaultChain","llmChainOpts","conversationChainOpts","multiRouteChainOpts"],"sources":["../../../src/chains/router/multi_prompt.d.ts"],"sourcesContent":["import type { BaseLanguageModelInterface } from \"@langchain/core/language_models/base\";\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nimport { MultiRouteChain, MultiRouteChainInput } from \"./multi_route.js\";\nimport { BaseChain } from \"../../chains/base.js\";\nimport { LLMChainInput } from \"../../chains/llm_chain.js\";\n/**\n * A class that represents a multi-prompt chain in the LangChain\n * framework. It extends the MultiRouteChain class and provides additional\n * functionality specific to multi-prompt chains.\n * @example\n * ```typescript\n * const multiPromptChain = MultiPromptChain.fromLLMAndPrompts(\n *   new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n *   {\n *     promptNames: [\"physics\", \"math\", \"history\"],\n *     promptDescriptions: [\n *       \"Good for answering questions about physics\",\n *       \"Good for answering math questions\",\n *       \"Good for answering questions about history\",\n *     ],\n *     promptTemplates: [\n *       `You are a very smart physics professor. Here is a question:\\n{input}\\n`,\n *       `You are a very good mathematician. Here is a question:\\n{input}\\n`,\n *       `You are a very smart history professor. Here is a question:\\n{input}\\n`,\n *     ],\n *   }\n * );\n * const result = await multiPromptChain.call({\n *   input: \"What is the speed of light?\",\n * });\n * ```\n */\nexport declare class MultiPromptChain extends MultiRouteChain {\n    /**\n     * @deprecated Use `fromLLMAndPrompts` instead\n     */\n    static fromPrompts(llm: BaseLanguageModelInterface, promptNames: string[], promptDescriptions: string[], promptTemplates: string[] | PromptTemplate[], defaultChain?: BaseChain, options?: Omit<MultiRouteChainInput, \"defaultChain\">): MultiPromptChain;\n    /**\n     * A static method that creates an instance of MultiPromptChain from a\n     * BaseLanguageModel and a set of prompts. It takes in optional parameters\n     * for the default chain and additional options.\n     * @param llm A BaseLanguageModel instance.\n     * @param promptNames An array of prompt names.\n     * @param promptDescriptions An array of prompt descriptions.\n     * @param promptTemplates An array of prompt templates.\n     * @param defaultChain An optional BaseChain instance to be used as the default chain.\n     * @param llmChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'prompt'.\n     * @param conversationChainOpts Optional parameters for the LLMChainInput, excluding 'llm' and 'outputKey'.\n     * @param multiRouteChainOpts Optional parameters for the MultiRouteChainInput, excluding 'defaultChain'.\n     * @returns An instance of MultiPromptChain.\n     */\n    static fromLLMAndPrompts(llm: BaseLanguageModelInterface, { promptNames, promptDescriptions, promptTemplates, defaultChain, llmChainOpts, conversationChainOpts, multiRouteChainOpts }: {\n        promptNames: string[];\n        promptDescriptions: string[];\n        promptTemplates: string[] | PromptTemplate[];\n        defaultChain?: BaseChain;\n        llmChainOpts?: Omit<LLMChainInput, \"llm\" | \"prompt\">;\n        conversationChainOpts?: Omit<LLMChainInput, \"llm\" | \"outputKey\">;\n        multiRouteChainOpts?: Omit<MultiRouteChainInput, \"defaultChain\">;\n    }): MultiPromptChain;\n    _chainType(): string;\n}\n"],"mappings":";;;;;;;;;;AAgCA;;;;;;;;;;;;;;;;;;;;;;;;;AAA8CE,cAAzBI,gBAAAA,SAAyBJ,eAAAA,CAAAA;EAAe;;;0BAIjCF,6GAA6GC,iCAAiCG,qBAAqBG,KAAKJ,wCAAwCG;;;;;;;;;;;;;;;gCAe1MN;;;;;;;;;;;gCAGEC;mBACbG;mBACAG,KAAKF;4BACIE,KAAKF;0BACPE,KAAKJ;MAC3BG"}