{"version":3,"file":"agent.cjs","names":["llm: BaseChatModel","tools: ObjectTool[]","AutoGPTOutputParser","AutoGPTPrompt","LLMChain","goals: string[]","HumanMessage","AIMessage","FINISH_NAME","result: string","SystemMessage"],"sources":["../../../src/experimental/autogpt/agent.ts"],"sourcesContent":["import type { VectorStoreRetrieverInterface } from \"@langchain/core/vectorstores\";\nimport { Tool } from \"@langchain/core/tools\";\nimport {\n  AIMessage,\n  BaseMessage,\n  HumanMessage,\n  SystemMessage,\n} from \"@langchain/core/messages\";\nimport { BaseChatModel } from \"@langchain/core/language_models/chat_models\";\nimport {\n  getEmbeddingContextSize,\n  getModelContextSize,\n} from \"@langchain/core/language_models/base\";\nimport { LLMChain } from \"../../chains/llm_chain.js\";\n\nimport { AutoGPTOutputParser } from \"./output_parser.js\";\nimport { AutoGPTPrompt } from \"./prompt.js\";\n// import { HumanInputRun } from \"./tools/human/tool\"; // TODO\nimport { ObjectTool, FINISH_NAME } from \"./schema.js\";\nimport { TokenTextSplitter } from \"../../text_splitter.js\";\n\n/**\n * Interface for the input parameters of the AutoGPT class.\n */\nexport interface AutoGPTInput {\n  aiName: string;\n  aiRole: string;\n  memory: VectorStoreRetrieverInterface;\n  humanInTheLoop?: boolean;\n  outputParser?: AutoGPTOutputParser;\n  maxIterations?: number;\n}\n\n/**\n * Class representing the AutoGPT concept with LangChain primitives. It is\n * designed to be used with a set of tools such as a search tool,\n * write-file tool, and a read-file tool.\n * @example\n * ```typescript\n * const autogpt = AutoGPT.fromLLMAndTools(\n *   new ChatOpenAI({ model: \"gpt-4o-mini\", temperature: 0 }),\n *   [\n *     new ReadFileTool({ store: new InMemoryFileStore() }),\n *     new WriteFileTool({ store: new InMemoryFileStore() }),\n *     new SerpAPI(\"YOUR_SERPAPI_API_KEY\", {\n *       location: \"San Francisco,California,United States\",\n *       hl: \"en\",\n *       gl: \"us\",\n *     }),\n *   ],\n *   {\n *     memory: new MemoryVectorStore(new OpenAIEmbeddings()).asRetriever(),\n *     aiName: \"Tom\",\n *     aiRole: \"Assistant\",\n *   },\n * );\n * const result = await autogpt.run([\"write a weather report for SF today\"]);\n * ```\n */\nexport class AutoGPT {\n  aiName: string;\n\n  memory: VectorStoreRetrieverInterface;\n\n  fullMessageHistory: BaseMessage[];\n\n  nextActionCount: number;\n\n  chain: LLMChain;\n\n  outputParser: AutoGPTOutputParser;\n\n  tools: ObjectTool[];\n\n  feedbackTool?: Tool;\n\n  maxIterations: number;\n\n  // Currently not generic enough to support any text splitter.\n  textSplitter: TokenTextSplitter;\n\n  constructor({\n    aiName,\n    memory,\n    chain,\n    outputParser,\n    tools,\n    feedbackTool,\n    maxIterations,\n  }: Omit<Required<AutoGPTInput>, \"aiRole\" | \"humanInTheLoop\"> & {\n    chain: LLMChain;\n    tools: ObjectTool[];\n    feedbackTool?: Tool;\n  }) {\n    this.aiName = aiName;\n    this.memory = memory;\n    this.fullMessageHistory = [];\n    this.nextActionCount = 0;\n    this.chain = chain;\n    this.outputParser = outputParser;\n    this.tools = tools;\n    this.feedbackTool = feedbackTool;\n    this.maxIterations = maxIterations;\n    const chunkSize = getEmbeddingContextSize(\n      \"modelName\" in memory.vectorStore.embeddings\n        ? (memory.vectorStore.embeddings.modelName as string)\n        : undefined\n    );\n    this.textSplitter = new TokenTextSplitter({\n      chunkSize,\n      chunkOverlap: Math.round(chunkSize / 10),\n    });\n  }\n\n  /**\n   * Creates a new AutoGPT instance from a given LLM and a set of tools.\n   * @param llm A BaseChatModel object.\n   * @param tools An array of ObjectTool objects.\n   * @param options.aiName The name of the AI.\n   * @param options.aiRole The role of the AI.\n   * @param options.memory A VectorStoreRetriever object that represents the memory of the AI.\n   * @param options.maxIterations The maximum number of iterations the AI can perform.\n   * @param options.outputParser An AutoGPTOutputParser object that parses the output of the AI.\n   * @returns A new instance of the AutoGPT class.\n   */\n  static fromLLMAndTools(\n    llm: BaseChatModel,\n    tools: ObjectTool[],\n    {\n      aiName,\n      aiRole,\n      memory,\n      maxIterations = 100,\n      // humanInTheLoop = false,\n      outputParser = new AutoGPTOutputParser(),\n    }: AutoGPTInput\n  ): AutoGPT {\n    const prompt = new AutoGPTPrompt({\n      aiName,\n      aiRole,\n      tools,\n      tokenCounter: llm.getNumTokens.bind(llm),\n      sendTokenLimit: getModelContextSize(\n        \"modelName\" in llm ? (llm.modelName as string) : \"gpt2\"\n      ),\n    });\n    // const feedbackTool = humanInTheLoop ? new HumanInputRun() : null;\n    const chain = new LLMChain({ llm, prompt });\n    return new AutoGPT({\n      aiName,\n      memory,\n      chain,\n      outputParser,\n      tools,\n      // feedbackTool,\n      maxIterations,\n    });\n  }\n\n  /**\n   * Runs the AI with a given set of goals.\n   * @param goals An array of strings representing the goals.\n   * @returns A string representing the result of the run or undefined if the maximum number of iterations is reached without a result.\n   */\n  async run(goals: string[]): Promise<string | undefined> {\n    const user_input =\n      \"Determine which next command to use, and respond using the format specified above:\";\n    let loopCount = 0;\n    while (loopCount < this.maxIterations) {\n      loopCount += 1;\n\n      const { text: assistantReply } = await this.chain.call({\n        goals,\n        user_input,\n        memory: this.memory,\n        messages: this.fullMessageHistory,\n      });\n\n      // Print the assistant reply\n      console.log(assistantReply);\n      this.fullMessageHistory.push(new HumanMessage(user_input));\n      this.fullMessageHistory.push(new AIMessage(assistantReply));\n\n      const action = await this.outputParser.parse(assistantReply);\n      const tools = this.tools.reduce(\n        (acc, tool) => ({ ...acc, [tool.name]: tool }),\n        {} as { [key: string]: ObjectTool }\n      );\n      if (action.name === FINISH_NAME) {\n        return action.args.response;\n      }\n      let result: string;\n      if (action.name in tools) {\n        const tool = tools[action.name];\n        let observation;\n        try {\n          observation = await tool.call(action.args);\n        } catch (e) {\n          observation = `Error in args: ${e}`;\n        }\n        result = `Command ${tool.name} returned: ${observation}`;\n      } else if (action.name === \"ERROR\") {\n        result = `Error: ${action.args}. `;\n      } else {\n        result = `Unknown command '${action.name}'. Please refer to the 'COMMANDS' list for available commands and only respond in the specified JSON format.`;\n      }\n\n      let memoryToAdd = `Assistant Reply: ${assistantReply}\\nResult: ${result} `;\n      if (this.feedbackTool) {\n        const feedback = `\\n${await this.feedbackTool.call(\"Input: \")}`;\n        if (feedback === \"q\" || feedback === \"stop\") {\n          console.log(\"EXITING\");\n          return \"EXITING\";\n        }\n        memoryToAdd += feedback;\n      }\n\n      const documents = await this.textSplitter.createDocuments([memoryToAdd]);\n      await this.memory.addDocuments(documents);\n      this.fullMessageHistory.push(new SystemMessage(result));\n    }\n\n    return undefined;\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA2DA,IAAa,UAAb,MAAa,QAAQ;CACnB;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAGA;CAEA,YAAY,EACV,QACA,QACA,OACA,cACA,OACA,cACA,eAKD,EAAE;EACD,KAAK,SAAS;EACd,KAAK,SAAS;EACd,KAAK,qBAAqB,CAAE;EAC5B,KAAK,kBAAkB;EACvB,KAAK,QAAQ;EACb,KAAK,eAAe;EACpB,KAAK,QAAQ;EACb,KAAK,eAAe;EACpB,KAAK,gBAAgB;EACrB,MAAM,+EACJ,eAAe,OAAO,YAAY,aAC7B,OAAO,YAAY,WAAW,YAC/B,OACL;EACD,KAAK,eAAe,gDAAI,kBAAkB;GACxC;GACA,cAAc,KAAK,MAAM,YAAY,GAAG;EACzC;CACF;;;;;;;;;;;;CAaD,OAAO,gBACLA,KACAC,OACA,EACE,QACA,QACA,QACA,gBAAgB,KAEhB,eAAe,IAAIC,6CACN,EACN;EACT,MAAM,SAAS,IAAIC,6BAAc;GAC/B;GACA;GACA;GACA,cAAc,IAAI,aAAa,KAAK,IAAI;GACxC,+EACE,eAAe,MAAO,IAAI,YAAuB,OAClD;EACF;EAED,MAAM,QAAQ,IAAIC,2BAAS;GAAE;GAAK;EAAQ;AAC1C,SAAO,IAAI,QAAQ;GACjB;GACA;GACA;GACA;GACA;GAEA;EACD;CACF;;;;;;CAOD,MAAM,IAAIC,OAA8C;EACtD,MAAM,aACJ;EACF,IAAI,YAAY;AAChB,SAAO,YAAY,KAAK,eAAe;GACrC,aAAa;GAEb,MAAM,EAAE,MAAM,gBAAgB,GAAG,MAAM,KAAK,MAAM,KAAK;IACrD;IACA;IACA,QAAQ,KAAK;IACb,UAAU,KAAK;GAChB,EAAC;GAGF,QAAQ,IAAI,eAAe;GAC3B,KAAK,mBAAmB,KAAK,IAAIC,uCAAa,YAAY;GAC1D,KAAK,mBAAmB,KAAK,IAAIC,oCAAU,gBAAgB;GAE3D,MAAM,SAAS,MAAM,KAAK,aAAa,MAAM,eAAe;GAC5D,MAAM,QAAQ,KAAK,MAAM,OACvB,CAAC,KAAK,UAAU;IAAE,GAAG;KAAM,KAAK,OAAO;GAAM,IAC7C,CAAE,EACH;AACD,OAAI,OAAO,SAASC,2BAClB,QAAO,OAAO,KAAK;GAErB,IAAIC;AACJ,OAAI,OAAO,QAAQ,OAAO;IACxB,MAAM,OAAO,MAAM,OAAO;IAC1B,IAAI;AACJ,QAAI;KACF,cAAc,MAAM,KAAK,KAAK,OAAO,KAAK;IAC3C,SAAQ,GAAG;KACV,cAAc,CAAC,eAAe,EAAE,GAAG;IACpC;IACD,SAAS,CAAC,QAAQ,EAAE,KAAK,KAAK,WAAW,EAAE,aAAa;GACzD,WAAU,OAAO,SAAS,SACzB,SAAS,CAAC,OAAO,EAAE,OAAO,KAAK,EAAE,CAAC;QAElC,SAAS,CAAC,iBAAiB,EAAE,OAAO,KAAK,4GAA4G,CAAC;GAGxJ,IAAI,cAAc,CAAC,iBAAiB,EAAE,eAAe,UAAU,EAAE,OAAO,CAAC,CAAC;AAC1E,OAAI,KAAK,cAAc;IACrB,MAAM,WAAW,CAAC,EAAE,EAAE,MAAM,KAAK,aAAa,KAAK,UAAU,EAAE;AAC/D,QAAI,aAAa,OAAO,aAAa,QAAQ;KAC3C,QAAQ,IAAI,UAAU;AACtB,YAAO;IACR;IACD,eAAe;GAChB;GAED,MAAM,YAAY,MAAM,KAAK,aAAa,gBAAgB,CAAC,WAAY,EAAC;GACxE,MAAM,KAAK,OAAO,aAAa,UAAU;GACzC,KAAK,mBAAmB,KAAK,IAAIC,wCAAc,QAAQ;EACxD;AAED,SAAO;CACR;AACF"}