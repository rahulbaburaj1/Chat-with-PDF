{"version":3,"file":"runner_utils.d.ts","names":["Runnable","Client","Feedback","TraceableFunction","RunEvalConfig","ChainOrFactory","AnyTraceableFunction","Promise","RunOnDatasetParams","Record","Omit","EvalResults","runOnDataset"],"sources":["../../src/smith/runner_utils.d.ts"],"sourcesContent":["import { Runnable } from \"@langchain/core/runnables\";\nimport { Client, Feedback } from \"langsmith\";\nimport type { TraceableFunction } from \"langsmith/singletons/traceable\";\nimport { type RunEvalConfig } from \"./config.js\";\nexport type ChainOrFactory = Runnable | (() => Runnable) | AnyTraceableFunction\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n | ((obj: any) => any)\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n | ((obj: any) => Promise<any>) | (() => (obj: unknown) => unknown) | (() => (obj: unknown) => Promise<unknown>);\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ntype AnyTraceableFunction = TraceableFunction<(...any: any[]) => any>;\nexport interface RunOnDatasetParams extends Omit<RunEvalConfig, \"customEvaluators\"> {\n    /**\n     * Name of the project for logging and tracking.\n     */\n    projectName?: string;\n    /**\n     * Additional metadata for the project.\n     */\n    projectMetadata?: Record<string, unknown>;\n    /**\n     * Client instance for LangSmith service interaction.\n     */\n    client?: Client;\n    /**\n     * Maximum concurrency level for dataset processing.\n     */\n    maxConcurrency?: number;\n    /**\n     * @deprecated Pass keys directly to the RunOnDatasetParams instead\n     */\n    evaluationConfig?: RunEvalConfig;\n}\nexport type EvalResults = {\n    projectName: string;\n    results: {\n        [key: string]: {\n            execution_time?: number;\n            run_id: string;\n            feedback: Feedback[];\n        };\n    };\n};\n/**\n * Evaluates a given model or chain against a specified LangSmith dataset.\n *\n * This function fetches example records from the specified dataset,\n * runs the model or chain against each example, and returns the evaluation\n * results.\n *\n * @param chainOrFactory - A model or factory/constructor function to be evaluated. It can be a\n * Runnable instance, a factory function that returns a Runnable, or a user-defined\n * function or factory.\n *\n * @param datasetName - The name of the dataset against which the evaluation will be\n * performed. This dataset should already be defined and contain the relevant data\n * for evaluation.\n *\n * @param options - (Optional) Additional parameters for the evaluation process:\n *   - `evaluators` (RunEvalType[]): Evaluators to apply to a dataset run.\n *   - `formatEvaluatorInputs` (EvaluatorInputFormatter): Convert the evaluation data into formats that can be used by the evaluator.\n *   - `projectName` (string): Name of the project for logging and tracking.\n *   - `projectMetadata` (Record<string, unknown>): Additional metadata for the project.\n *   - `client` (Client): Client instance for LangSmith service interaction.\n *   - `maxConcurrency` (number): Maximum concurrency level for dataset processing.\n *\n * @returns A promise that resolves to an `EvalResults` object. This object includes\n * detailed results of the evaluation, such as execution time, run IDs, and feedback\n * for each entry in the dataset.\n *\n * @example\n * ```typescript\n * // Example usage for evaluating a model on a dataset\n * async function evaluateModel() {\n *   const chain = /* ...create your model or chain...*\\//\n *   const datasetName = 'example-dataset';\n *   const client = new Client(/* ...config... *\\//);\n *\n *   const results = await runOnDataset(chain, datasetName, {\n *     evaluators: [/* ...evaluators... *\\//],\n *     client,\n *   });\n *\n *   console.log('Evaluation Results:', results);\n * }\n *\n * evaluateModel();\n * ```\n * In this example, `runOnDataset` is used to evaluate a language model (or a chain of models) against\n * a dataset named 'example-dataset'. The evaluation process is configured using `RunOnDatasetParams[\"evaluators\"]`, which can\n * include both standard and custom evaluators. The `Client` instance is used to interact with LangChain services.\n * The function returns the evaluation results, which can be logged or further processed as needed.\n */\nexport declare function runOnDataset(chainOrFactory: ChainOrFactory, datasetName: string, options?: RunOnDatasetParams): Promise<EvalResults>;\nexport {};\n"],"mappings":";;;;;;KAIYK,cAAAA,GAAiBL,kBAAkBA,YAAYM;;EAA3D,CAAYD,CAAAA,GAAAA,EAAAA,GAAAA,EAAAA,GAAAA,GAAc;;EAAA,CAAA,CAAA,GAAGL,EAAAA,GAAAA,EAAAA,GAIXO,OAJWP,CAAAA,GAAAA,CAAAA,CAAAA,GAAAA,CAAAA,GAAAA,GAAAA,CAAAA,GAAAA,EAAAA,OAAAA,EAAAA,GAAAA,OAAAA,CAAAA,GAAAA,CAAAA,GAAAA,GAAAA,CAAAA,GAAAA,EAAAA,OAAAA,EAAAA,GAIkEO,OAJlEP,CAAAA,OAAAA,CAAAA,CAAAA;;KAMxBM,oBAAAA,GAAuBH,iBAN+BG,CAAAA,CAAAA,GAAAA,GAAAA,EAAAA,GAAAA,EAAAA,EAAAA,GAAAA,GAAAA,CAAAA;AAIzCC,UAGDC,kBAAAA,SAA2BE,IAH1BH,CAG+BH,aAH/BG,EAAAA,kBAAAA,CAAAA,CAAAA;EAAO;AAA6E;AAAW;EAGhGC,WAAAA,CAAAA,EAAAA,MAAAA;EAAkB;;;EAQP,eAIfP,CAAAA,EAJSQ,MAITR,CAAAA,MAAAA,EAAAA,OAAAA,CAAAA;EAAM;;AAZ6B;EAsBpCU,MAAAA,CAAAA,EAVCV,MAUU;EA4DCW;;;EAA2C,cAAiCJ,CAAAA,EAAAA,MAAAA;EAAkB;;AAAU;qBA9DzGJ;;KAEXO,WAAAA;;;;;;gBAMUT;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;iBAsDEU,YAAAA,iBAA6BP,+CAA+CG,qBAAqBD,QAAQI"}