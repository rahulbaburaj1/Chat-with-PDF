{"version":3,"file":"index.d.cts","names":["BaseChatModelParams","ChatTencentHunyuan","BaseChatTencentHunyuan","TencentHunyuanChatInput","Partial"],"sources":["../../../src/chat_models/tencent_hunyuan/index.d.ts"],"sourcesContent":["import { type BaseChatModelParams } from \"@langchain/core/language_models/chat_models\";\nimport { ChatTencentHunyuan as BaseChatTencentHunyuan, TencentHunyuanChatInput } from \"./base.js\";\n/**\n * Wrapper around Tencent Hunyuan large language models that use the Chat endpoint.\n *\n * To use you should have the `TENCENT_SECRET_ID` and `TENCENT_SECRET_KEY`\n * environment variable set.\n *\n * @augments BaseLLM\n * @augments TencentHunyuanInput\n * @example\n * ```typescript\n * const messages = [new HumanMessage(\"Hello\")];\n *\n * const hunyuanLite = new ChatTencentHunyuan({\n *   model: \"hunyuan-lite\",\n *   tencentSecretId: \"YOUR-SECRET-ID\",\n *   tencentSecretKey: \"YOUR-SECRET-KEY\",\n * });\n *\n * let res = await hunyuanLite.call(messages);\n *\n * const hunyuanPro = new ChatTencentHunyuan({\n *   model: \"hunyuan-pro\",\n *   temperature: 1,\n *   tencentSecretId: \"YOUR-SECRET-ID\",\n *   tencentSecretKey: \"YOUR-SECRET-KEY\",\n * });\n *\n * res = await hunyuanPro.call(messages);\n * ```\n */\nexport declare class ChatTencentHunyuan extends BaseChatTencentHunyuan {\n    constructor(fields?: Partial<TencentHunyuanChatInput> & BaseChatModelParams);\n}\nexport type { TencentHunyuanChatInput } from \"./base.js\";\n"],"mappings":";;;;;;;;;;;;;;;AAgCA;;;;;;AAAsE;;;;;;;;;;;;;;;;cAAjDC,oBAAAA,SAA2BC,kBAAAA;uBACvBE,QAAQD,2BAA2BH"}