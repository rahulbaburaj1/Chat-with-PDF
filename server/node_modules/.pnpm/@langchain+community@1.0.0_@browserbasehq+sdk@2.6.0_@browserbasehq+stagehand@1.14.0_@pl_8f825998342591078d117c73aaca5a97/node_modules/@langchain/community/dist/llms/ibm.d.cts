import { Neverify, WatsonxAuth, WatsonxDeployedParams, WatsonxParams } from "../types/ibm.cjs";
import { BaseLanguageModelCallOptions } from "@langchain/core/language_models/base";
import { RequestCallbacks, ReturnOptionProperties, TextGenLengthPenalty, TextGenParameters, TextTokenizeParameters } from "@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js";
import { GenerationChunk, LLMResult } from "@langchain/core/outputs";
import { CallbackManagerForLLMRun } from "@langchain/core/callbacks/manager";
import { BaseLLM, BaseLLMParams } from "@langchain/core/language_models/llms";

//#region src/llms/ibm.d.ts
declare namespace ibm_d_exports {
  export { WatsonxCallOptionsLLM, WatsonxDeployedInputLLM, WatsonxDeploymentLLMParams, WatsonxInputLLM, WatsonxLLM, WatsonxLLMConstructor, WatsonxLLMParams };
}
/**
 * Input to LLM class.
 */
interface WatsonxLLMParams {
  maxNewTokens?: number;
  decodingMethod?: TextGenParameters.Constants.DecodingMethod | string;
  lengthPenalty?: TextGenLengthPenalty;
  minNewTokens?: number;
  randomSeed?: number;
  stopSequence?: string[];
  temperature?: number;
  timeLimit?: number;
  topK?: number;
  topP?: number;
  repetitionPenalty?: number;
  truncateInpuTokens?: number;
  returnOptions?: ReturnOptionProperties;
  includeStopSequence?: boolean;
}
interface WatsonxDeploymentLLMParams {
  idOrName: string;
}
interface WatsonxCallOptionsLLM extends BaseLanguageModelCallOptions {
  maxRetries?: number;
  parameters?: Partial<WatsonxLLMParams>;
  watsonxCallbacks?: RequestCallbacks;
}
interface WatsonxInputLLM extends WatsonxParams, BaseLLMParams, WatsonxLLMParams, Neverify<WatsonxDeploymentLLMParams> {}
interface WatsonxDeployedInputLLM extends WatsonxDeployedParams, BaseLLMParams, Neverify<WatsonxLLMParams> {
  model?: never;
}
type WatsonxLLMConstructor = BaseLLMParams & WatsonxLLMParams & Partial<WatsonxParams> & WatsonxDeployedParams;
/**
 * Integration with an LLM.
 */
declare class WatsonxLLM<CallOptions extends WatsonxCallOptionsLLM = WatsonxCallOptionsLLM> extends BaseLLM<CallOptions> implements WatsonxLLMConstructor {
  // Used for tracing, replace with the same name as your class
  static lc_name(): string;
  lc_serializable: boolean;
  streaming: boolean;
  model: string;
  maxRetries: number;
  version: string;
  serviceUrl: string;
  maxNewTokens?: number;
  spaceId?: string;
  projectId?: string;
  idOrName?: string;
  decodingMethod?: TextGenParameters.Constants.DecodingMethod | string;
  lengthPenalty?: TextGenLengthPenalty;
  minNewTokens?: number;
  randomSeed?: number;
  stopSequence?: string[];
  temperature?: number;
  timeLimit?: number;
  topK?: number;
  topP?: number;
  repetitionPenalty?: number;
  truncateInpuTokens?: number;
  returnOptions?: ReturnOptionProperties;
  includeStopSequence?: boolean;
  maxConcurrency?: number;
  watsonxCallbacks?: RequestCallbacks;
  private service;
  constructor(fields: (WatsonxInputLLM | WatsonxDeployedInputLLM) & WatsonxAuth);
  get lc_secrets(): {
    [key: string]: string;
  };
  get lc_aliases(): {
    [key: string]: string;
  };
  invocationParams(options: this["ParsedCallOptions"]): {
    max_new_tokens: number | undefined;
    decoding_method: string | undefined;
    length_penalty: TextGenLengthPenalty | undefined;
    min_new_tokens: number | undefined;
    random_seed: number | undefined;
    stop_sequences: string[] | undefined;
    temperature: number | undefined;
    time_limit: number | undefined;
    top_k: number | undefined;
    top_p: number | undefined;
    repetition_penalty: number | undefined;
    truncate_input_tokens: number | undefined;
    return_options: ReturnOptionProperties | undefined;
    include_stop_sequence: boolean | undefined;
  } | undefined;
  invocationCallbacks(options: this["ParsedCallOptions"]): RequestCallbacks<any> | undefined;
  scopeId(): {
    spaceId?: undefined;
    projectId: string;
    modelId: string;
    idOrName?: undefined;
  } | {
    projectId?: undefined;
    spaceId: string;
    modelId: string;
    idOrName?: undefined;
  } | {
    projectId?: undefined;
    spaceId?: undefined;
    idOrName: string;
    modelId: string;
  } | {
    projectId?: undefined;
    spaceId?: undefined;
    idOrName?: undefined;
    modelId: string;
  };
  listModels(): Promise<string[] | undefined>;
  private generateSingleMessage;
  completionWithRetry<T>(callback: () => T, options?: this["ParsedCallOptions"]): Promise<T>;
  _generate(prompts: string[], options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): Promise<LLMResult>;
  getNumTokens(content: string, options?: TextTokenizeParameters): Promise<number>;
  _streamResponseChunks(prompt: string, options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<GenerationChunk>;
  _llmType(): string;
}
//#endregion
export { WatsonxCallOptionsLLM, WatsonxDeployedInputLLM, WatsonxDeploymentLLMParams, WatsonxInputLLM, WatsonxLLM, WatsonxLLMConstructor, WatsonxLLMParams, ibm_d_exports };
//# sourceMappingURL=ibm.d.cts.map