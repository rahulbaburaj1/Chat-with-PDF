{"version":3,"file":"alibaba_tongyi.d.ts","names":["CallbackManagerForLLMRun","BaseChatModel","BaseChatModelParams","BaseMessage","ChatResult","ChatGenerationChunk","TongyiMessageRole","TongyiMessage","ChatCompletionRequest","NonNullable","AlibabaTongyiChatInput","ChatAlibabaTongyi","Partial","Pick","Promise","AbortSignal","MessageEvent","AsyncGenerator"],"sources":["../../src/chat_models/alibaba_tongyi.d.ts"],"sourcesContent":["import { type CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { BaseChatModel, type BaseChatModelParams } from \"@langchain/core/language_models/chat_models\";\nimport { type BaseMessage } from \"@langchain/core/messages\";\nimport { type ChatResult } from \"@langchain/core/outputs\";\nimport { ChatGenerationChunk } from \"@langchain/core/outputs\";\n/**\n * Type representing the role of a message in the Tongyi chat model.\n */\nexport type TongyiMessageRole = \"system\" | \"assistant\" | \"user\";\n/**\n * Interface representing a message in the Tongyi chat model.\n */\ninterface TongyiMessage {\n    role: TongyiMessageRole;\n    content: string;\n}\n/**\n * Interface representing a request for a chat completion.\n *\n * See https://help.aliyun.com/zh/dashscope/developer-reference/model-square/\n */\ninterface ChatCompletionRequest {\n    model: (string & NonNullable<unknown>) | \"qwen-turbo\" | \"qwen-plus\" | \"qwen-max\" | \"qwen-max-1201\" | \"qwen-max-longcontext\"\n    // 通义千问开源系列\n     | \"qwen-7b-chat\" | \"qwen-14b-chat\" | \"qwen-72b-chat\"\n    // LLAMA2\n     | \"llama2-7b-chat-v2\" | \"llama2-13b-chat-v2\"\n    // 百川\n     | \"baichuan-7b-v1\" | \"baichuan2-13b-chat-v1\" | \"baichuan2-7b-chat-v1\"\n    // ChatGLM\n     | \"chatglm3-6b\" | \"chatglm-6b-v2\";\n    input: {\n        messages: TongyiMessage[];\n    };\n    parameters: {\n        stream?: boolean;\n        result_format?: \"text\" | \"message\";\n        seed?: number | null;\n        max_tokens?: number | null;\n        top_p?: number | null;\n        top_k?: number | null;\n        repetition_penalty?: number | null;\n        temperature?: number | null;\n        enable_search?: boolean | null;\n        incremental_output?: boolean | null;\n    };\n}\n/**\n * Interface defining the input to the ChatAlibabaTongyi class.\n */\ninterface AlibabaTongyiChatInput {\n    /**\n     * Model name to use. Available options are: qwen-turbo, qwen-plus, qwen-max, or Other compatible models.\n     * Alias for `model`\n     * @default \"qwen-turbo\"\n     */\n    modelName: string;\n    /** Model name to use. Available options are: qwen-turbo, qwen-plus, qwen-max, or Other compatible models.\n     * @default \"qwen-turbo\"\n     */\n    model: string;\n    /** Whether to stream the results or not. Defaults to false. */\n    streaming?: boolean;\n    /** Messages to pass as a prefix to the prompt */\n    prefixMessages?: TongyiMessage[];\n    /**\n     * API key to use when making requests. Defaults to the value of\n     * `ALIBABA_API_KEY` environment variable.\n     */\n    alibabaApiKey?: string;\n    /** Amount of randomness injected into the response. Ranges\n     * from 0 to 1 (0 is not included). Use temp closer to 0 for analytical /\n     * multiple choice, and temp closer to 1 for creative\n     * and generative tasks. Defaults to 0.95.\n     */\n    temperature?: number;\n    /** Total probability mass of tokens to consider at each step. Range\n     * from 0 to 1.0. Defaults to 0.8.\n     */\n    topP?: number;\n    topK?: number;\n    enableSearch?: boolean;\n    maxTokens?: number;\n    seed?: number;\n    /** Penalizes repeated tokens according to frequency. Range\n     * from 1.0 to 2.0. Defaults to 1.0.\n     */\n    repetitionPenalty?: number;\n}\n/**\n * Wrapper around Ali Tongyi large language models that use the Chat endpoint.\n *\n * To use you should have the `ALIBABA_API_KEY`\n * environment variable set.\n *\n * @augments BaseLLM\n * @augments AlibabaTongyiInput\n * @example\n * ```typescript\n * const qwen = new ChatAlibabaTongyi({\n *   alibabaApiKey: \"YOUR-API-KEY\",\n * });\n *\n * const qwen = new ChatAlibabaTongyi({\n *   model: \"qwen-turbo\",\n *   temperature: 1,\n *   alibabaApiKey: \"YOUR-API-KEY\",\n * });\n *\n * const messages = [new HumanMessage(\"Hello\")];\n *\n * await qwen.call(messages);\n * ```\n */\nexport declare class ChatAlibabaTongyi extends BaseChatModel implements AlibabaTongyiChatInput {\n    static lc_name(): string;\n    get callKeys(): string[];\n    get lc_secrets(): {\n        alibabaApiKey: string;\n    };\n    get lc_aliases(): undefined;\n    lc_serializable: boolean;\n    alibabaApiKey?: string;\n    streaming: boolean;\n    prefixMessages?: TongyiMessage[];\n    modelName: ChatCompletionRequest[\"model\"];\n    model: ChatCompletionRequest[\"model\"];\n    apiUrl: string;\n    maxTokens?: number | undefined;\n    temperature?: number | undefined;\n    topP?: number | undefined;\n    topK?: number | undefined;\n    repetitionPenalty?: number | undefined;\n    seed?: number | undefined;\n    enableSearch?: boolean | undefined;\n    constructor(fields?: Partial<AlibabaTongyiChatInput> & BaseChatModelParams);\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(): ChatCompletionRequest[\"parameters\"];\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams(): ChatCompletionRequest[\"parameters\"] & Pick<ChatCompletionRequest, \"model\">;\n    /** @ignore */\n    _generate(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    /** @ignore */\n    completionWithRetry(request: ChatCompletionRequest, stream: boolean, signal?: AbortSignal, onmessage?: (event: MessageEvent) => void): Promise<any>;\n    _streamResponseChunks(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    private createTongyiStream;\n    _llmType(): string;\n    /** @ignore */\n    _combineLLMOutput(): never[];\n}\nexport {};\n"],"mappings":";;;;;;;;;;;;KAQYM,iBAAAA;;;;AAAZ,UAIUC,aAAAA,CAJmB;EAInBA,IAAAA,EACAD,iBADa;EASbE,OAAAA,EAAAA,MAAAA;;;;AAWqB;AAAA;AAkF/B;UA7FUA,qBAAAA,CA6F4B;EAAA,KAUjBD,EAAAA,CAAAA,MAAAA,GAtGAE,WAsGAF,CAAAA,OAAAA,CAAAA,CAAAA,GAAAA,YAAAA,GAAAA,WAAAA,GAAAA,UAAAA,GAAAA,eAAAA,GAAAA;EAAa;EAAA,EAEvBC,cAAAA,GAAAA,eAAAA,GAAAA;EAAqB;EAAA,EASPI,mBAAAA,GAAAA;EAAO;EAAA,EAIRJ,gBAAAA,GAAAA,uBAAAA,GAAAA;EAAqB;EAAA,EAIuBA,aAAAA,GAAAA,eAAAA;EAAqB,KAA1BK,EAAAA;IAEvCV,QAAAA,EAjHNI,aAiHMJ,EAAAA;EAAW,CAAA;EAA8E,UAAWC,EAAAA;IAARU,MAAAA,CAAAA,EAAAA,OAAAA;IAEnFN,aAAAA,CAAAA,EAAAA,MAAAA,GAAAA,SAAAA;IAAiDO,IAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IAAiCC,UAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IAAwBF,KAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IACvGX,KAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IAAiEH,kBAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IAA0CK,WAAAA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;IAAfY,aAAAA,CAAAA,EAAAA,OAAAA,GAAAA,IAAAA;IAlCjFhB,kBAAAA,CAAAA,EAAAA,OAAAA,GAAAA,IAAAA;EAAa,CAAA;AAAkC;;;;UAhEpFS,sBAAAA;;;;;;;;;;;;;;mBAcWH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cAkDAI,iBAAAA,SAA0BV,aAAAA,YAAyBS;;;;;;;;;;mBAUnDH;aACNC;SACJA;;;;;;;;;uBAScI,QAAQF,0BAA0BR;;;;sBAInCM;;;;uBAICA,sCAAsCK,KAAKL;;sBAE5CL,iEAAiEH,2BAA2Bc,QAAQV;;+BAE3FI,iDAAiDO,iCAAiCC,wBAAwBF;kCACvGX,iEAAiEH,2BAA2BiB,eAAeZ"}