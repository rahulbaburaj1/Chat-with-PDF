{"version":3,"file":"raycast.cjs","names":["ms: number","LLM","fields: RaycastAIInput","environment","AI","prompt: string","options: this[\"ParsedCallOptions\"]"],"sources":["../../src/llms/raycast.ts"],"sourcesContent":["import { AI, environment } from \"@raycast/api\";\nimport { LLM, type BaseLLMParams } from \"@langchain/core/language_models/llms\";\n\n/**\n * The input parameters for the RaycastAI class, which extends the BaseLLMParams interface.\n */\nexport interface RaycastAIInput extends BaseLLMParams {\n  model?: AI.Model;\n  creativity?: number;\n  rateLimitPerMinute?: number;\n}\n\nconst wait = (ms: number) =>\n  new Promise((resolve) => {\n    setTimeout(resolve, ms);\n  });\n\n/**\n * The RaycastAI class, which extends the LLM class and implements the RaycastAIInput interface.\n */\nexport class RaycastAI extends LLM implements RaycastAIInput {\n  lc_serializable = true;\n\n  /**\n   * The model to use for generating text.\n   */\n  model: AI.Model;\n\n  /**\n   * The creativity parameter, also known as the \"temperature\".\n   */\n  creativity: number;\n\n  /**\n   * The rate limit for API calls, in requests per minute.\n   */\n  rateLimitPerMinute: number;\n\n  /**\n   * The timestamp of the last API call, used to enforce the rate limit.\n   */\n  private lastCallTimestamp = 0;\n\n  /**\n   * Creates a new instance of the RaycastAI class.\n   * @param {RaycastAIInput} fields The input parameters for the RaycastAI class.\n   * @throws {Error} If the Raycast AI environment is not accessible.\n   */\n  constructor(fields: RaycastAIInput) {\n    super(fields ?? {});\n\n    if (!environment.canAccess(AI)) {\n      throw new Error(\"Raycast AI environment is not accessible.\");\n    }\n\n    if (fields.model === undefined) {\n      throw new Error(`You must provide a \"model\" field in your params.`);\n    }\n\n    this.model = fields.model;\n    this.creativity = fields.creativity ?? 0.5;\n    this.rateLimitPerMinute = fields.rateLimitPerMinute ?? 10;\n  }\n\n  /**\n   * Returns the type of the LLM, which is \"raycast_ai\".\n   * @return {string} The type of the LLM.\n   * @ignore\n   */\n  _llmType() {\n    return \"raycast_ai\";\n  }\n\n  /**\n   * Calls AI.ask with the given prompt and returns the generated text.\n   * @param {string} prompt The prompt to generate text from.\n   * @return {Promise<string>} A Promise that resolves to the generated text.\n   * @ignore\n   */\n  async _call(\n    prompt: string,\n    options: this[\"ParsedCallOptions\"]\n  ): Promise<string> {\n    const response = await this.caller.call(async () => {\n      // Rate limit calls to Raycast AI\n      const now = Date.now();\n      const timeSinceLastCall = now - this.lastCallTimestamp;\n      const timeToWait =\n        (60 / this.rateLimitPerMinute) * 1000 - timeSinceLastCall;\n\n      if (timeToWait > 0) {\n        await wait(timeToWait);\n      }\n\n      return await AI.ask(prompt, {\n        model: this.model,\n        creativity: this.creativity,\n        signal: options.signal,\n      });\n    });\n\n    // Since Raycast AI returns the response directly, no need for output transformation\n    return response;\n  }\n}\n"],"mappings":";;;;;;;AAYA,MAAM,OAAO,CAACA,OACZ,IAAI,QAAQ,CAAC,YAAY;CACvB,WAAW,SAAS,GAAG;AACxB;;;;AAKH,IAAa,YAAb,cAA+BC,0CAA8B;CAC3D,kBAAkB;;;;CAKlB;;;;CAKA;;;;CAKA;;;;CAKA,AAAQ,oBAAoB;;;;;;CAO5B,YAAYC,QAAwB;EAClC,MAAM,UAAU,CAAE,EAAC;AAEnB,MAAI,CAACC,0BAAY,UAAUC,iBAAG,CAC5B,OAAM,IAAI,MAAM;AAGlB,MAAI,OAAO,UAAU,OACnB,OAAM,IAAI,MAAM,CAAC,gDAAgD,CAAC;EAGpE,KAAK,QAAQ,OAAO;EACpB,KAAK,aAAa,OAAO,cAAc;EACvC,KAAK,qBAAqB,OAAO,sBAAsB;CACxD;;;;;;CAOD,WAAW;AACT,SAAO;CACR;;;;;;;CAQD,MAAM,MACJC,QACAC,SACiB;EACjB,MAAM,WAAW,MAAM,KAAK,OAAO,KAAK,YAAY;GAElD,MAAM,MAAM,KAAK,KAAK;GACtB,MAAM,oBAAoB,MAAM,KAAK;GACrC,MAAM,aACH,KAAK,KAAK,qBAAsB,MAAO;AAE1C,OAAI,aAAa,GACf,MAAM,KAAK,WAAW;AAGxB,UAAO,MAAMF,iBAAG,IAAI,QAAQ;IAC1B,OAAO,KAAK;IACZ,YAAY,KAAK;IACjB,QAAQ,QAAQ;GACjB,EAAC;EACH,EAAC;AAGF,SAAO;CACR;AACF"}