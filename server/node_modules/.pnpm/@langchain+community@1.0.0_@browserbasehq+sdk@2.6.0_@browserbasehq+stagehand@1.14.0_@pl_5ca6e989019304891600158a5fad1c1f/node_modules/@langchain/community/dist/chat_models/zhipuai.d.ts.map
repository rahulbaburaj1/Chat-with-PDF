{"version":3,"file":"zhipuai.d.ts","names":["BaseChatModel","BaseChatModelParams","BaseMessage","ChatGenerationChunk","ChatResult","CallbackManagerForLLMRun","ZhipuMessageRole","ZhipuMessage","ModelName","NonNullable","ChatCompletionRequest","ChatZhipuAIParams","ChatZhipuAI","Partial","Omit","Promise","AbortSignal","MessageEvent","AsyncGenerator"],"sources":["../../src/chat_models/zhipuai.d.ts"],"sourcesContent":["import { BaseChatModel, type BaseChatModelParams } from \"@langchain/core/language_models/chat_models\";\nimport { type BaseMessage } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk, type ChatResult } from \"@langchain/core/outputs\";\nimport { type CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nexport type ZhipuMessageRole = \"system\" | \"assistant\" | \"user\";\ninterface ZhipuMessage {\n    role: ZhipuMessageRole;\n    content: string;\n}\n/**\n * Interface representing a request for a chat completion.\n *\n * See https://open.bigmodel.cn/dev/howuse/model\n */\ntype ModelName = (string & NonNullable<unknown>)\n// will be deprecated models\n | \"chatglm_pro\" // deprecated in 2024-12-31T23:59:59+0800，point to glm-4\n | \"chatglm_std\" // deprecated in 2024-12-31T23:59:59+0800，point to glm-3-turbo\n | \"chatglm_lite\" // deprecated in 2024-12-31T23:59:59+0800，point to glm-3-turbo\n// GLM-4 more powerful on Q/A and text generation, suitable for complex dialog interactions and deep content creation design.\n | \"glm-4\" // context size: 128k\n | \"glm-4v\" // context size: 2k\n// ChatGLM-Turbo\n | \"glm-3-turbo\" // context size: 128k\n | \"chatglm_turbo\"; // context size: 32k\ninterface ChatCompletionRequest {\n    model: ModelName;\n    messages?: ZhipuMessage[];\n    do_sample?: boolean;\n    stream?: boolean;\n    request_id?: string;\n    max_tokens?: number | null;\n    top_p?: number | null;\n    top_k?: number | null;\n    temperature?: number | null;\n    stop?: string[];\n}\n/**\n * Interface defining the input to the ZhipuAIChatInput class.\n */\nexport interface ChatZhipuAIParams {\n    /**\n     * @default \"glm-3-turbo\"\n     * Alias for `model`\n     */\n    modelName: ModelName;\n    /**\n     * @default \"glm-3-turbo\"\n     */\n    model: ModelName;\n    /** Whether to stream the results or not. Defaults to false. */\n    streaming?: boolean;\n    /** Messages to pass as a prefix to the prompt */\n    messages?: ZhipuMessage[];\n    /**\n     * API key to use when making requests. Defaults to the value of\n     * `ZHIPUAI_API_KEY` environment variable.\n     * Alias for `apiKey`\n     */\n    zhipuAIApiKey?: string;\n    /**\n     * API key to use when making requests. Defaults to the value of\n     * `ZHIPUAI_API_KEY` environment variable.\n     */\n    apiKey?: string;\n    /** Amount of randomness injected into the response. Ranges\n     * from 0 to 1 (0 is not included). Use temp closer to 0 for analytical /\n     * multiple choice, and temp closer to 1 for creative\n     * and generative tasks. Defaults to 0.95\n     */\n    temperature?: number;\n    /** Total probability mass of tokens to consider at each step. Range\n     * from 0 to 1 Defaults to 0.7\n     */\n    topP?: number;\n    /**\n     * Unique identifier for the request. Defaults to a random UUID.\n     */\n    requestId?: string;\n    /**\n     * turn on sampling strategy when do_sample is true,\n     * do_sample is false, temperature、top_p will not take effect\n     */\n    doSample?: boolean;\n    /**\n     * max value is 8192，defaults to 1024\n     */\n    maxTokens?: number;\n    stop?: string[];\n}\nexport declare class ChatZhipuAI extends BaseChatModel implements ChatZhipuAIParams {\n    static lc_name(): string;\n    get callKeys(): string[];\n    get lc_secrets(): {\n        zhipuAIApiKey: string;\n        apiKey: string;\n    };\n    get lc_aliases(): undefined;\n    zhipuAIApiKey?: string;\n    apiKey?: string;\n    streaming: boolean;\n    doSample?: boolean;\n    messages?: ZhipuMessage[];\n    requestId?: string;\n    modelName: ChatCompletionRequest[\"model\"];\n    model: ChatCompletionRequest[\"model\"];\n    apiUrl: string;\n    maxTokens?: number | undefined;\n    temperature?: number | undefined;\n    topP?: number | undefined;\n    stop?: string[];\n    constructor(fields?: Partial<ChatZhipuAIParams> & BaseChatModelParams);\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(): Omit<ChatCompletionRequest, \"messages\">;\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams(): Omit<ChatCompletionRequest, \"messages\">;\n    /** @ignore */\n    _generate(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;\n    /** @ignore */\n    completionWithRetry(request: ChatCompletionRequest, stream: boolean, signal?: AbortSignal, onmessage?: (event: MessageEvent) => void): Promise<any>;\n    private createZhipuStream;\n    private _deserialize;\n    _streamResponseChunks(messages: BaseMessage[], options?: this[\"ParsedCallOptions\"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;\n    _llmType(): string;\n    /** @ignore */\n    _combineLLMOutput(): never[];\n}\nexport {};\n"],"mappings":";;;;;;;;;KAIYM,gBAAAA;UACFC,YAAAA;QACAD;;;;;;;AAFV;AAA+D,KAU1DE,SAAAA,GATKD,CAAAA,MAAY,GASKE,WARjBH,CAAAA,OAAAA,CAAgB;AAAA;AAAA,EAQY,aAW5BI,CAAAA;AAAAA,EAAqB,aAAA,CAAA;AAAA,EAAA,cACpBF,CAAAA;;EACgB,OAAA,CAAA;AAAA,EAa3B,QAAiBG,CAAAA;;EAAiB,aAKnBH,CAAAA;AAAAA,EAAS,eAIbA,CAAAA,CAAAA;UAxBDE,qBAAAA,CA4BKH;EAAY,KAAA,EA3BhBC,SA2BgB;EAqCNI,QAAAA,CAAAA,EA/DNL,YA+DiB,EAAA;EAAA,SAAA,CAAA,EAAA,OAAA;EAAA,MAYjBA,CAAAA,EAAAA,OAAAA;EAAY,UAEZG,CAAAA,EAAAA,MAAAA;EAAqB,UACzBA,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAAqB,KAMCC,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAAiB,KAAzBE,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAAO,WAAsBZ,CAAAA,EAAAA,MAAAA,GAAAA,IAAAA;EAAmB,IAI5CS,CAAAA,EAAAA,MAAAA,EAAAA;;;;;AAM4DL,UAjFxEM,iBAAAA,CAiFwEN;EAAwB;;;;EAEpB,SAAsBY,EA9EpGT,SA8EoGS;EAAY;;;EAGF,KAAkBd,EA7EpIK,SA6EoIL;EAAmB;EAApB,SApCrGH,CAAAA,EAAAA,OAAAA;EAAa;EAA6B,QAAA,CAAA,EArCpEO,YAqCoE,EAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;cAA9DK,WAAAA,SAAoBZ,aAAAA,YAAyBW;;;;;;;;;;;;aAYnDJ;;aAEAG;SACJA;;;;;;uBAMcG,QAAQF,qBAAqBV;;;;sBAI9Ba,KAAKJ;;;;uBAIJI,KAAKJ;;sBAENR,iEAAiEG,2BAA2BU,QAAQX;;+BAE3FM,iDAAiDM,iCAAiCC,wBAAwBF;;;kCAGvGb,iEAAiEG,2BAA2Ba,eAAef"}