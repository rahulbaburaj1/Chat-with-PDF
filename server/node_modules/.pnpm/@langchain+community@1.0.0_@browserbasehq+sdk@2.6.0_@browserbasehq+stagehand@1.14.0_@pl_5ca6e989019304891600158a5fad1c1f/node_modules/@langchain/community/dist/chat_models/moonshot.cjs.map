{"version":3,"file":"moonshot.cjs","names":["message: BaseMessage","ChatMessage","BaseChatModel","fields: Partial<ChatMoonshotParams> & BaseChatModelParams","messages: BaseMessage[]","options?: this[\"ParsedCallOptions\"]","runManager?: CallbackManagerForLLMRun","messagesMapped: MoonshotMessage[]","response: ChatCompletionResponse","data: ChatCompletionResponse","data","text","AIMessage","request: ChatCompletionRequest","stream: boolean","signal?: AbortSignal","onmessage?: (event: MessageEvent) => void","value"],"sources":["../../src/chat_models/moonshot.ts"],"sourcesContent":["import {\n  BaseChatModel,\n  type BaseChatModelParams,\n} from \"@langchain/core/language_models/chat_models\";\nimport {\n  AIMessage,\n  type BaseMessage,\n  ChatMessage,\n} from \"@langchain/core/messages\";\nimport { type ChatResult } from \"@langchain/core/outputs\";\nimport { type CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\n\nexport type MoonshotMessageRole = \"system\" | \"assistant\" | \"user\";\n\ninterface MoonshotMessage {\n  role: MoonshotMessageRole;\n  content: string;\n}\n\n/**\n * Interface representing a request for a chat completion.\n *\n * See https://platform.moonshot.cn/docs/intro#%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8\n */\ntype ModelName =\n  | (string & NonNullable<unknown>)\n  | \"moonshot-v1-8k\" // context size: 8k\n  | \"moonshot-v1-32k\" // context size: 32k\n  | \"moonshot-v1-128k\"; // context size: 128k\ninterface ChatCompletionRequest {\n  model: ModelName;\n  messages?: MoonshotMessage[];\n  stream?: boolean;\n  max_tokens?: number | null;\n  top_p?: number | null;\n  temperature?: number | null;\n  stop?: string[];\n  presence_penalty?: number;\n  frequency_penalty?: number;\n  n?: number;\n}\n\ninterface BaseResponse {\n  code?: string;\n  message?: string;\n}\n\ninterface ChoiceMessage {\n  role: string;\n  content: string;\n}\n\ninterface ResponseChoice {\n  index: number;\n  finish_reason: \"stop\" | \"length\" | \"null\" | null;\n  delta: ChoiceMessage;\n  message: ChoiceMessage;\n}\n\n/**\n * Interface representing a response from a chat completion.\n */\ninterface ChatCompletionResponse extends BaseResponse {\n  choices: ResponseChoice[];\n  created: number;\n  id: string;\n  model: string;\n  request_id: string;\n  usage: {\n    completion_tokens: number;\n    prompt_tokens: number;\n    total_tokens: number;\n  };\n  output: {\n    text: string;\n    finish_reason: \"stop\" | \"length\" | \"null\" | null;\n  };\n}\n\n/**\n * Interface defining the input to the MoonshotChatInput class.\n */\nexport interface ChatMoonshotParams {\n  /**\n   * @default \"moonshot-v1-8k\"\n   * Alias for `model`\n   */\n  modelName: ModelName;\n  /**\n   * @default \"moonshot-v1-8k\"\n   */\n  model: ModelName;\n\n  /** Whether to stream the results or not. Defaults to false. */\n  streaming?: boolean;\n\n  /** Messages to pass as a prefix to the prompt */\n  messages?: MoonshotMessage[];\n\n  /**\n   * API key to use when making requests. Defaults to the value of\n   * `MOONSHOT_API_KEY` environment variable.\n   */\n  apiKey?: string;\n\n  /**\n   * Amount of randomness injected into the response. Ranges\n   * from 0 to 1 (0 is not included). Use temp closer to 0 for analytical /\n   * multiple choice, and temp closer to 1 for creative and generative tasks.\n   * Defaults to 0, recommended 0.3\n   */\n  temperature?: number;\n\n  /**\n   * Total probability mass of tokens to consider at each step. Range\n   * from 0 to 1. Defaults to 1\n   */\n  topP?: number;\n\n  /**\n   * Different models have different maximum values. For example, the maximum\n   * value of moonshot-v1-8k is 8192. Defaults to 1024\n   */\n  maxTokens?: number;\n\n  stop?: string[];\n\n  /**\n   * There is a penalty, a number between -2.0 and 2.0. Positive values\n   * penalize the newly generated words based on whether they appear in the\n   * text, increasing the likelihood that the model will discuss new topics.\n   * The default value is 0\n   */\n  presencePenalty?: number;\n\n  /**\n   * Frequency penalty, a number between -2.0 and 2.0. Positive values\n   * penalize the newly generated words based on their existing frequency in the\n   * text, making the model less likely to repeat the same words verbatim.\n   * The default value is 0\n   */\n  frequencyPenalty?: number;\n\n  /**\n   * The default value is 1 and cannot be greater than 5. In particular,\n   * when temperature is very small and close to 0, we can only return 1 result.\n   * If n is already set and > 1, Moonshot will return an invalid input parameter\n   * (invalid_request_error).\n   */\n  n?: number;\n}\n\nfunction messageToRole(message: BaseMessage): MoonshotMessageRole {\n  const type = message._getType();\n  switch (type) {\n    case \"ai\":\n      return \"assistant\";\n    case \"human\":\n      return \"user\";\n    case \"system\":\n      return \"system\";\n    case \"function\":\n      throw new Error(\"Function messages not supported yet\");\n    case \"generic\": {\n      if (!ChatMessage.isInstance(message)) {\n        throw new Error(\"Invalid generic chat message\");\n      }\n      if ([\"system\", \"assistant\", \"user\"].includes(message.role)) {\n        return message.role as MoonshotMessageRole;\n      }\n      throw new Error(`Unknown message type: ${type}`);\n    }\n    default:\n      throw new Error(`Unknown message type: ${type}`);\n  }\n}\n\nexport class ChatMoonshot extends BaseChatModel implements ChatMoonshotParams {\n  static lc_name() {\n    return \"ChatMoonshot\";\n  }\n\n  get callKeys() {\n    return [\"stop\", \"signal\", \"options\"];\n  }\n\n  get lc_secrets() {\n    return {\n      apiKey: \"MOONSHOT_API_KEY\",\n    };\n  }\n\n  get lc_aliases() {\n    return undefined;\n  }\n\n  apiKey?: string;\n\n  streaming: boolean;\n\n  messages?: MoonshotMessage[];\n\n  modelName: ChatCompletionRequest[\"model\"];\n\n  model: ChatCompletionRequest[\"model\"];\n\n  apiUrl: string;\n\n  maxTokens?: number | undefined;\n\n  temperature?: number | undefined;\n\n  topP?: number | undefined;\n\n  stop?: string[];\n\n  presencePenalty?: number;\n\n  frequencyPenalty?: number;\n\n  n?: number;\n\n  constructor(fields: Partial<ChatMoonshotParams> & BaseChatModelParams = {}) {\n    super(fields);\n\n    this.apiKey = fields?.apiKey ?? getEnvironmentVariable(\"MOONSHOT_API_KEY\");\n\n    if (!this.apiKey) {\n      throw new Error(\"Moonshot API key not found\");\n    }\n\n    this.apiUrl = \"https://api.moonshot.cn/v1/chat/completions\";\n    this.streaming = fields.streaming ?? false;\n    this.messages = fields.messages ?? [];\n    this.temperature = fields.temperature ?? 0;\n    this.topP = fields.topP ?? 1;\n    this.stop = fields.stop;\n    this.maxTokens = fields.maxTokens;\n    this.modelName = fields?.model ?? fields.modelName ?? \"moonshot-v1-8k\";\n    this.model = this.modelName;\n    this.presencePenalty = fields.presencePenalty ?? 0;\n    this.frequencyPenalty = fields.frequencyPenalty ?? 0;\n    this.n = fields.n ?? 1;\n  }\n\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(): Omit<ChatCompletionRequest, \"messages\"> {\n    return {\n      model: this.model,\n      stream: this.streaming,\n      temperature: this.temperature,\n      top_p: this.topP,\n      max_tokens: this.maxTokens,\n      stop: this.stop,\n      presence_penalty: this.presencePenalty,\n      frequency_penalty: this.frequencyPenalty,\n      n: this.n,\n    };\n  }\n\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams(): Omit<ChatCompletionRequest, \"messages\"> {\n    return this.invocationParams();\n  }\n\n  /** @ignore */\n  async _generate(\n    messages: BaseMessage[],\n    options?: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<ChatResult> {\n    const parameters = this.invocationParams();\n\n    const messagesMapped: MoonshotMessage[] = messages.map((message) => ({\n      role: messageToRole(message),\n      content: message.content as string,\n    }));\n\n    const data = parameters.stream\n      ? await new Promise<ChatCompletionResponse>((resolve, reject) => {\n          let response: ChatCompletionResponse;\n          let rejected = false;\n          let resolved = false;\n          this.completionWithRetry(\n            {\n              ...parameters,\n              messages: messagesMapped,\n            },\n            true,\n            options?.signal,\n            (event) => {\n              const data: ChatCompletionResponse = JSON.parse(event.data);\n              if (data?.code) {\n                if (rejected) {\n                  return;\n                }\n                rejected = true;\n                reject(new Error(data?.message));\n                return;\n              }\n\n              const { delta, finish_reason } = data.choices[0];\n              const text = delta.content;\n\n              if (!response) {\n                response = {\n                  ...data,\n                  output: { text, finish_reason },\n                };\n              } else {\n                response.output.text += text;\n                response.output.finish_reason = finish_reason;\n                response.usage = data.usage;\n              }\n\n              // eslint-disable-next-line no-void\n              void runManager?.handleLLMNewToken(text ?? \"\");\n              if (finish_reason && finish_reason !== \"null\") {\n                if (resolved || rejected) return;\n                resolved = true;\n                resolve(response);\n              }\n            }\n          ).catch((error) => {\n            if (!rejected) {\n              rejected = true;\n              reject(error);\n            }\n          });\n        })\n      : await this.completionWithRetry(\n          {\n            ...parameters,\n            messages: messagesMapped,\n          },\n          false,\n          options?.signal\n        ).then<ChatCompletionResponse>((data) => {\n          if (data?.code) {\n            throw new Error(data?.message);\n          }\n          const { finish_reason, message } = data.choices[0];\n          const text = message.content;\n          return {\n            ...data,\n            output: { text, finish_reason },\n          };\n        });\n\n    const {\n      prompt_tokens = 0,\n      completion_tokens = 0,\n      total_tokens = 0,\n    } = data.usage ?? {};\n\n    const { text } = data.output;\n\n    return {\n      generations: [\n        {\n          text,\n          message: new AIMessage(text),\n        },\n      ],\n      llmOutput: {\n        tokenUsage: {\n          promptTokens: prompt_tokens,\n          completionTokens: completion_tokens,\n          totalTokens: total_tokens,\n        },\n      },\n    };\n  }\n\n  /** @ignore */\n  async completionWithRetry(\n    request: ChatCompletionRequest,\n    stream: boolean,\n    signal?: AbortSignal,\n    onmessage?: (event: MessageEvent) => void\n  ) {\n    const makeCompletionRequest = async () => {\n      const response = await fetch(this.apiUrl, {\n        method: \"POST\",\n        headers: {\n          ...(stream ? { Accept: \"text/event-stream\" } : {}),\n          Authorization: `Bearer ${this.apiKey}`,\n          \"Content-Type\": \"application/json\",\n        },\n        body: JSON.stringify(request),\n        signal,\n      });\n\n      if (!stream) {\n        return response.json();\n      }\n\n      if (response.body) {\n        // response will not be a stream if an error occurred\n        if (\n          !response.headers.get(\"content-type\")?.startsWith(\"text/event-stream\")\n        ) {\n          onmessage?.(\n            new MessageEvent(\"message\", {\n              data: await response.text(),\n            })\n          );\n          return;\n        }\n        const reader = response.body.getReader();\n        const decoder = new TextDecoder(\"utf-8\");\n        let data = \"\";\n        let continueReading = true;\n        while (continueReading) {\n          const { done, value } = await reader.read();\n          if (done) {\n            continueReading = false;\n            break;\n          }\n          data += decoder.decode(value);\n          let continueProcessing = true;\n          while (continueProcessing) {\n            const newlineIndex = data.indexOf(\"\\n\");\n            if (newlineIndex === -1) {\n              continueProcessing = false;\n              break;\n            }\n            const line = data.slice(0, newlineIndex);\n            data = data.slice(newlineIndex + 1);\n            if (line.startsWith(\"data:\")) {\n              const value = line.slice(\"data:\".length).trim();\n              if (value === \"[DONE]\") {\n                continueReading = false;\n                break;\n              }\n              const event = new MessageEvent(\"message\", { data: value });\n              onmessage?.(event);\n            }\n          }\n        }\n      }\n    };\n\n    return this.caller.call(makeCompletionRequest);\n  }\n\n  _llmType(): string {\n    return \"moonshot\";\n  }\n\n  /** @ignore */\n  _combineLLMOutput() {\n    return [];\n  }\n}\n"],"mappings":";;;;;;;;AAyJA,SAAS,cAAcA,SAA2C;CAChE,MAAM,OAAO,QAAQ,UAAU;AAC/B,SAAQ,MAAR;EACE,KAAK,KACH,QAAO;EACT,KAAK,QACH,QAAO;EACT,KAAK,SACH,QAAO;EACT,KAAK,WACH,OAAM,IAAI,MAAM;EAClB,KAAK;AACH,OAAI,CAACC,sCAAY,WAAW,QAAQ,CAClC,OAAM,IAAI,MAAM;AAElB,OAAI;IAAC;IAAU;IAAa;GAAO,EAAC,SAAS,QAAQ,KAAK,CACxD,QAAO,QAAQ;AAEjB,SAAM,IAAI,MAAM,CAAC,sBAAsB,EAAE,MAAM;EAEjD,QACE,OAAM,IAAI,MAAM,CAAC,sBAAsB,EAAE,MAAM;CAClD;AACF;AAED,IAAa,eAAb,cAAkCC,2DAA4C;CAC5E,OAAO,UAAU;AACf,SAAO;CACR;CAED,IAAI,WAAW;AACb,SAAO;GAAC;GAAQ;GAAU;EAAU;CACrC;CAED,IAAI,aAAa;AACf,SAAO,EACL,QAAQ,mBACT;CACF;CAED,IAAI,aAAa;AACf,SAAO;CACR;CAED;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,YAAYC,SAA4D,CAAE,GAAE;EAC1E,MAAM,OAAO;EAEb,KAAK,SAAS,QAAQ,iEAAiC,mBAAmB;AAE1E,MAAI,CAAC,KAAK,OACR,OAAM,IAAI,MAAM;EAGlB,KAAK,SAAS;EACd,KAAK,YAAY,OAAO,aAAa;EACrC,KAAK,WAAW,OAAO,YAAY,CAAE;EACrC,KAAK,cAAc,OAAO,eAAe;EACzC,KAAK,OAAO,OAAO,QAAQ;EAC3B,KAAK,OAAO,OAAO;EACnB,KAAK,YAAY,OAAO;EACxB,KAAK,YAAY,QAAQ,SAAS,OAAO,aAAa;EACtD,KAAK,QAAQ,KAAK;EAClB,KAAK,kBAAkB,OAAO,mBAAmB;EACjD,KAAK,mBAAmB,OAAO,oBAAoB;EACnD,KAAK,IAAI,OAAO,KAAK;CACtB;;;;CAKD,mBAA4D;AAC1D,SAAO;GACL,OAAO,KAAK;GACZ,QAAQ,KAAK;GACb,aAAa,KAAK;GAClB,OAAO,KAAK;GACZ,YAAY,KAAK;GACjB,MAAM,KAAK;GACX,kBAAkB,KAAK;GACvB,mBAAmB,KAAK;GACxB,GAAG,KAAK;EACT;CACF;;;;CAKD,oBAA6D;AAC3D,SAAO,KAAK,kBAAkB;CAC/B;;CAGD,MAAM,UACJC,UACAC,SACAC,YACqB;EACrB,MAAM,aAAa,KAAK,kBAAkB;EAE1C,MAAMC,iBAAoC,SAAS,IAAI,CAAC,aAAa;GACnE,MAAM,cAAc,QAAQ;GAC5B,SAAS,QAAQ;EAClB,GAAE;EAEH,MAAM,OAAO,WAAW,SACpB,MAAM,IAAI,QAAgC,CAAC,SAAS,WAAW;GAC7D,IAAIC;GACJ,IAAI,WAAW;GACf,IAAI,WAAW;GACf,KAAK,oBACH;IACE,GAAG;IACH,UAAU;GACX,GACD,MACA,SAAS,QACT,CAAC,UAAU;IACT,MAAMC,SAA+B,KAAK,MAAM,MAAM,KAAK;AAC3D,QAAIC,QAAM,MAAM;AACd,SAAI,SACF;KAEF,WAAW;KACX,OAAO,IAAI,MAAMA,QAAM,SAAS;AAChC;IACD;IAED,MAAM,EAAE,OAAO,eAAe,GAAGA,OAAK,QAAQ;IAC9C,MAAMC,SAAO,MAAM;AAEnB,QAAI,CAAC,UACH,WAAW;KACT,GAAGD;KACH,QAAQ;MAAE;MAAM;KAAe;IAChC;SACI;KACL,SAAS,OAAO,QAAQC;KACxB,SAAS,OAAO,gBAAgB;KAChC,SAAS,QAAQD,OAAK;IACvB;IAGI,YAAY,kBAAkBC,UAAQ,GAAG;AAC9C,QAAI,iBAAiB,kBAAkB,QAAQ;AAC7C,SAAI,YAAY,SAAU;KAC1B,WAAW;KACX,QAAQ,SAAS;IAClB;GACF,EACF,CAAC,MAAM,CAAC,UAAU;AACjB,QAAI,CAAC,UAAU;KACb,WAAW;KACX,OAAO,MAAM;IACd;GACF,EAAC;EACH,KACD,MAAM,KAAK,oBACT;GACE,GAAG;GACH,UAAU;EACX,GACD,OACA,SAAS,OACV,CAAC,KAA6B,CAACD,WAAS;AACvC,OAAIA,QAAM,KACR,OAAM,IAAI,MAAMA,QAAM;GAExB,MAAM,EAAE,eAAe,SAAS,GAAGA,OAAK,QAAQ;GAChD,MAAMC,SAAO,QAAQ;AACrB,UAAO;IACL,GAAGD;IACH,QAAQ;KAAE;KAAM;IAAe;GAChC;EACF,EAAC;EAEN,MAAM,EACJ,gBAAgB,GAChB,oBAAoB,GACpB,eAAe,GAChB,GAAG,KAAK,SAAS,CAAE;EAEpB,MAAM,EAAE,MAAM,GAAG,KAAK;AAEtB,SAAO;GACL,aAAa,CACX;IACE;IACA,SAAS,IAAIE,oCAAU;GACxB,CACF;GACD,WAAW,EACT,YAAY;IACV,cAAc;IACd,kBAAkB;IAClB,aAAa;GACd,EACF;EACF;CACF;;CAGD,MAAM,oBACJC,SACAC,QACAC,QACAC,WACA;EACA,MAAM,wBAAwB,YAAY;GACxC,MAAM,WAAW,MAAM,MAAM,KAAK,QAAQ;IACxC,QAAQ;IACR,SAAS;KACP,GAAI,SAAS,EAAE,QAAQ,oBAAqB,IAAG,CAAE;KACjD,eAAe,CAAC,OAAO,EAAE,KAAK,QAAQ;KACtC,gBAAgB;IACjB;IACD,MAAM,KAAK,UAAU,QAAQ;IAC7B;GACD,EAAC;AAEF,OAAI,CAAC,OACH,QAAO,SAAS,MAAM;AAGxB,OAAI,SAAS,MAAM;AAEjB,QACE,CAAC,SAAS,QAAQ,IAAI,eAAe,EAAE,WAAW,oBAAoB,EACtE;KACA,YACE,IAAI,aAAa,WAAW,EAC1B,MAAM,MAAM,SAAS,MAAM,CAC5B,GACF;AACD;IACD;IACD,MAAM,SAAS,SAAS,KAAK,WAAW;IACxC,MAAM,UAAU,IAAI,YAAY;IAChC,IAAI,OAAO;IACX,IAAI,kBAAkB;AACtB,WAAO,iBAAiB;KACtB,MAAM,EAAE,MAAM,OAAO,GAAG,MAAM,OAAO,MAAM;AAC3C,SAAI,MAAM;MACR,kBAAkB;AAClB;KACD;KACD,QAAQ,QAAQ,OAAO,MAAM;KAC7B,IAAI,qBAAqB;AACzB,YAAO,oBAAoB;MACzB,MAAM,eAAe,KAAK,QAAQ,KAAK;AACvC,UAAI,iBAAiB,IAAI;OACvB,qBAAqB;AACrB;MACD;MACD,MAAM,OAAO,KAAK,MAAM,GAAG,aAAa;MACxC,OAAO,KAAK,MAAM,eAAe,EAAE;AACnC,UAAI,KAAK,WAAW,QAAQ,EAAE;OAC5B,MAAMC,UAAQ,KAAK,MAAM,EAAe,CAAC,MAAM;AAC/C,WAAIA,YAAU,UAAU;QACtB,kBAAkB;AAClB;OACD;OACD,MAAM,QAAQ,IAAI,aAAa,WAAW,EAAE,MAAMA,QAAO;OACzD,YAAY,MAAM;MACnB;KACF;IACF;GACF;EACF;AAED,SAAO,KAAK,OAAO,KAAK,sBAAsB;CAC/C;CAED,WAAmB;AACjB,SAAO;CACR;;CAGD,oBAAoB;AAClB,SAAO,CAAE;CACV;AACF"}